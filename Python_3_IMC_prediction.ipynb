{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beecbc70",
   "metadata": {},
   "source": [
    "# Partie 3 : Premiers pas vers les méthodes de ML supervisé en python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c721ac0",
   "metadata": {},
   "source": [
    "L'idée de cette partie est de tester différentes méthodes d'apprentissage statistique supervisées usuelles. Pour cela nous allons utiliser les données issues de la table de description des individus interviewés lors de l'enquête INCA 3 sur la consommation et les habitudes alimentaires des français.\n",
    "\n",
    "L'objectif consistera à prédire au mieux l'IMC d'un individu grâce aux diverses informations que nous détenons sur la personne. Contrairement à la partie 2 sur le clustering, il s'agit ici de d'apprentissage supervisé car nous avons en notre possessions des données labélisées. Parmi les méthodes d'apprentissages supervisé on distingue généralement deux grandes familles que sont la classification et la régression. Ici nous sommes confronté à un problème de régression puisque nous souhaitons prédire l'indice de masse corporelle exacte. Pour cela nous allons tester plusieurs méthodes différentes afin d'analyser lesquelles sont les plus efficaces sur les données que nous possédons.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c510f9",
   "metadata": {},
   "source": [
    "## 1. Prise en main des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65b5d4b1",
   "metadata": {},
   "source": [
    "Les données de l'enquête INCA3 sont disponibles sur *Data.gouv* à l'adresse suivante : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/. Cette table contient les données des questionnaires face-à-face relatifs aux volets « Socio-économique » et « Mesures anthropométriques » et des données des questionnaires auto-administrés relatifs aux volets « Etat de santé » et « Tabagisme ». \n",
    "\n",
    "Elle regroupe les informations suivantes : caractéristiques socio-démographiques de l’individu (ou de son représentant dans le cas des enfants), caractéristiques\n",
    "socio-démographiques de la personne de référence du foyer, niveau de vie du foyer, insécurité alimentaire, caractéristiques anthropométriques (poids, taille, indice\n",
    "de masse corporelle, statut pondéral) ; statut vis-à-vis d’allergies ou d’intolérances alimentaires, types de régimes alimentaires, types d’allergies ou d’intolérances\n",
    "alimentaires, régimes et histoire pondérale, statut vis-à-vis de la grossesse, de l’allaitement et de la ménopause (uniquement pour les femmes de 15 ans et plus),\n",
    "statut tabagique ; indicateurs de sous ou sur-déclaration en termes de consommations alimentaires.\n",
    "\n",
    "Nous avons préalablement selectionné un grand nombre de variables issues de cette base que nous avons ensuite enregistré dans un bucket s3. Vous pouvez les télécharger grâce à ma commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow import fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430475",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
    "\n",
    "bucket = \"projet-funathon\"\n",
    "path_data =  \"2023/sujet3/diffusion/description_individu_inca.parquet\"\n",
    "\n",
    "df = pq.ParquetDataset(f'{bucket}/{path_data}', filesystem=s3).read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63af787d",
   "metadata": {},
   "source": [
    "<i  class=\"fa fa-pencil\"></i> On peut tout d'abord remarquer que le jeu de données ne semble, a priori, pas idéal pour réaliser des méthodes de machine learning très complexes avec beaucoup de paramètres à estimer. Il arrive très souvent que des méthodes plus classiques soient aussi, voire plus, efficaces que les méthodes d'apprentissage statistique. Cependant ce jeu de données peut tout à fait être utilisé à des fins pédagogiques pour comprendre les principes généraux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20461c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ae1b18",
   "metadata": {},
   "source": [
    "Tout d'abord, commençons par définir quelques constantes qui nous seront utiles pour la suite, à savoir : \n",
    "- La variable d'intérêt que nous cherchons à prédire `TARGET_VARIABLE`\n",
    "- La variable correspondant au numéro d'individu `NOIND`\n",
    "- Un nombre arbitraire pour afin de simplifier la réplicabilité de nos expérimentations `SEED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afeedb4-ef62-4ca3-bde7-8c81e20c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VARIABLE=\"imc\"\n",
    "INDEX=\"NOIND\"\n",
    "SEED=2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e98384fd",
   "metadata": {},
   "source": [
    "**Question 1:** Comme souvent en science de la données, la partie la plus fastidieuse consiste à analyser les données à notre disposition. En vous aidant du dictionnaire accessible [ici](https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf) déterminer l'ensemble des variables numériques. Les autres variables seront considérées comme des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\n",
    "# REMPLIR ICI\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24b78538",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997bff29",
   "metadata": {},
   "source": [
    "Une pratique courante dans les projets de machine learning c'est de commencer par spécifier une fraction de notre jeu données comme un **échantillon de test**. Cet échantillon va être utilisé à la toute fin du projet de sorte à évaluer la performance de nos modèles sur des données qu'il n'aura jamais vu auparavant. L'échantillon restant, celui **d'entrainement**, est lui utilisé pour entrainer les algorithmes et comparer leurs performances. L'idée derrière cette division est de réduire le risque de sur-apprentissage de notre modèle et d'estimer une erreur de généralisation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935d6713",
   "metadata": {},
   "source": [
    "**Question 2:** Créer les variables `y` et `X` correspondant respectivement à la variable d'intérêt et aux différentes features de notre jeu de données. Diviser ensuite ce jeu de données en un échantillon de train et de test en utilisant la fonction `train_test_split` de [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Ne pas oublier de spécifier le `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Votre code ici"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a3dba9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_VARIABLE]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f174eaa4",
   "metadata": {},
   "source": [
    "## 2. Un modèle de régression linéaire simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d324b88",
   "metadata": {},
   "source": [
    "**Question 3:** Avant d'étudier différentes méthodes d'apprentissage statistique commençons par réaliser une régression linéaire classique. Pour cela, sélectionnez un petit nombre de variables $(< 10)$ qui vous semble pertinent pour prédire l'indice de masse corporelle d'une personne. Prenez à la fois des variables numériques et catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd56601",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_REGRESSION = [\n",
    "# A REMPLIR\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "# A REMPLIR\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5beca656",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "   # \"tage_PS_mois\",\n",
    "   # \"diplome_interv\",\n",
    "   # \"soins\",\n",
    "   # \"situ_fin_3cl\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "   # \"IA_statut\",\n",
    "   # \"statnut\",\n",
    "    \"poids_perception\" ,\n",
    "   # \"menopause\",\n",
    "    \"enceinte\",\n",
    "   # \"enceinte_12dermois\",\n",
    "   # 'etude_4cl_interv',\n",
    "   # 'situ_prof_5cl_interv',\n",
    "   # 'atrav_interv',\n",
    "   # 'trav_nuit_interv',\n",
    "   # 'trav_nuit_2cl_interv',\n",
    "   # 'PCS_8cl_interv',\n",
    "   # 'PCS_4cl_interv',\n",
    "   # 'tps_travail_interv',\n",
    "   # 'vacances_interv',\n",
    "   # 'RUC_4cl',\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "   # \"bmr_kcal\",\n",
    "   # 'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5068cd-d2f1-4edd-a5e3-2e131c7c39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train[FEATURES_REGRESSION]\n",
    "X_test_regression = X_test[FEATURES_REGRESSION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87529e-74d9-49e4-a1bf-ed597d3cf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a2ebf40",
   "metadata": {},
   "source": [
    "Ces informations nous indiquent qu'il y a plusieurs variables qui contiennent des valeurs manquantes. Afin de ne pas supprimer les lignes qui contiennent des valeurs manquantes nous allons tenter de les imputer. Plusieurs méthodes d'imputations peuvent être réalisées :\n",
    "\n",
    "- **Pour les variables numériques:** Il est courant de remplacer les variables manquantes par la moyenne ou la médiane de l'échantillon.\n",
    "- **Pour les variables catégorielles:** On peut remplacer les variables manquantes par le moden c'est à dire la valeur la plus fréquente dans l'échantillon ou en créant une nouvelle categorie reflétant une valeur manquante.\n",
    "\n",
    "D'autres méthodes qui requiert plus de modélisation sont également possible comme réaliser une régression afin de prédire les valeurs manquantes grâce aux autres features ou  utiliser un algorithme de K plus proche voisin. Toutes ces méthodes ont à la fois leurs avantages et leurs inconvénients, il est important de déterminer celle qui est la plus approprié pour le problème que vous souhaitez résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cf28e27",
   "metadata": {},
   "source": [
    "**Question 4:** Pour faire simple, nous allons remplacer les valeurs manquantes des variables numériques par la médiane et pour celles des variables catégorielles nous allons créer une nouvelle catégorie qui sera égale à $-1$. Ce dernier choix vous semble t-il approprié ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b0f2dc",
   "metadata": {},
   "source": [
    "**Question 5:** En vous aidant de la (documentation)[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute] de scikit learn , créez ces deux *Imputer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = # YOUR CODE\n",
    "median_imputer = # YOUR CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b74119c3",
   "metadata": {},
   "source": [
    "**Question 6:** Analysez les modalités de la variables `enceinte_nbmois`, une imputation par la moyenne vous semble-t-elle justifiée ? Si non, proposez une autre imputation. Existe t-il d'autres variables dans ce cas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03399840",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pd.unique(X_train_regression[\"enceinte_nbmois\"])\n",
    "```\n",
    "\n",
    "```python\n",
    "# Les valeurs manquantes correspondent plutôt à la modalité \"pas enceinte\", il est donc plus judicieux de remplacer les valeurs manquantes par 0.\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ded42c4",
   "metadata": {},
   "source": [
    "Une étape très importante lorsqu'on utilise des méthodes de machine learning est la standardisation des données afin de mettre toutes les variables à la même échelle. Lorsque les variables ont des échelles différentes, certaines peuvent dominer les autres dans le processus d'apprentissage, ce qui peut fausser les résultats. Plusieurs méthodes de standardisation peuvent être utilisées, les deux plus courantes sont: \n",
    "- la normalisation standard : $z = \\frac{x - \\bar{x}}{\\sigma}$\n",
    "- la normalisation 0-1 : $z = \\frac{x - min}{max - min}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aa43ba5",
   "metadata": {},
   "source": [
    "Nous pouvons donc créer une pipeline dans laquelle nos *features* passeront afin de subir diverses transformations. En l'occurence, nous souhaitons que nos les valeurs manquantes *features* soient imputées et que ces dernières soit standardisées. Pour cela nous pouvons utiliser la fonction `make_pipeline`. Pour le *scaler* nous allons utiliser la normalisation standard qui peut être réalisée grâce à la méthode `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc77a99",
   "metadata": {},
   "source": [
    "Une fois nos *pipelines* définies ils faut déterminer quelles *features* passent par quelles *pipelines*. Dans notre cas, on souhaite que les variables catégorielles traversent la pipeline qui impute les valeurs manquantes par $-1$ et les variables numériques par la pipeline qui impute soit par la médiane, soit par 0. Pour cela on doit utiliser la fonction `ColumnTransformer`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc634d2",
   "metadata": {},
   "source": [
    "**Question 7:** En vous référant à la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) de la fonction, créez votre pipeline de preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    #YOUR CODE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ed35c11",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89cd6074",
   "metadata": {},
   "source": [
    "Maintenant que nos étapes de *preprocessing* sont définies, on peut les réaliser et observer les changements qui ont été opéré sur notre jeu de données afin de vérifier que les modifications ont bien été faites comme attendues. Pour cela, commencons par observer notre échantillon d'entrainement initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3c039f",
   "metadata": {},
   "source": [
    "Jusqu'à présent nous avons seulement définies les étapes de notre *preprocessing* mais celles ci n'ont pas été réalisées, pour cela nous devons `fit` notre preprocessing à notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_regression.fit(X_train_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_regression.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71788e0d",
   "metadata": {},
   "source": [
    "Scikit learn juxtapose automatiquement le nom de la transformation effectuée à la variable. Pour simplifier la comparaison nous allons supprimer ce qui a été rajouté en prefixe de sorte à retrouver les même nom de variable qu'initialement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "original_feature_names = [re.sub(r'^.*__', '', item) for item in preprocessor_regression.get_feature_names_out()]\n",
    "original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.DataFrame(preprocessor_regression.fit_transform(X_train_regression), columns=original_feature_names)\n",
    "data_preprocessed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2858a55b",
   "metadata": {},
   "source": [
    "Une fois qu'on a vérifié que le preprocessing nous convient on peut analyser la corrélation des différentes variables explicatives pour se prévenir du problème de la collinéarité. Pour cela, rien de mieux qu'une visualisation graphique pour obtenir une première idée !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0701761e",
   "metadata": {},
   "source": [
    "**Question 8:** Calculer la matrice de correlation des variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = # YOUR CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "553eb31a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "corr = data_preprocessed.corr()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ff894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee93e9e",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant passer à la modélisation ! Sachant qu'on a déjà une *pipeline* qui contient les instructions pour le preprocessing il est très simple de rajouter une étape supplémentaire à cette pipeline afin de réaliser la modélisation. Pour estimer une régression linéaire nous allons utiliser une nouvelle fois une méthode de scikit-learn: `LinearRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor_regression), # 1ère étape réaliser le preprocessing\n",
    "    ('regression', LinearRegression()) # 2ème étape estime notre régression linéaire\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f85295d1",
   "metadata": {},
   "source": [
    "Comme précédemment, notre pipeline n'a pas été exécutée, nous l'avons seulement définie. Il est donc nécessaire de l'executer sur nos données grâce à la méthode `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pipe_lr.fit(X_train_regression, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e140c2",
   "metadata": {},
   "source": [
    "**Question 9:** Prédisez les indices de masse corporelles des individus de votre échantillon de test à l'aide de votre modèle. Evaluez le en calculant l'écart quadratique moyen (RMSE) et le R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = # YOUR CODE\n",
    "rmse = # YOUR CODE\n",
    "r2 = # YOUR CODE\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26894458",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = lr.predict(X_test_regression)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ac4506",
   "metadata": {},
   "source": [
    "Il est difficile d'interpréter la valeur absolue du RMSE car il dépend de l'échelle et de la volatilité des données que nous cherchons à prédire. Regardons quelques statistiques de nl'IMC de nos individus de l'échantillons de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La variance de l'IMC de jeu de test est : {round(y_test.var(), 4)}\")\n",
    "print(f\"La moyenne de l'IMC de jeu de test est : {round(y_test.mean(), 4)}\")\n",
    "print(f\"L'écart interquartile de l'IMC de jeu de test est : {round(y_test.quantile(0.75) - y_test.quantile(0.25), 4)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95c10717",
   "metadata": {},
   "source": [
    "On peut donc normaliser notre RMSE par l'une de ces statistiques pour avoir une idée plus précise des erreurs. La variance et la moyenne sont généralement les plus utilisées pour normaliser le RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4628e2d1",
   "metadata": {},
   "source": [
    "Une autre méthode qu'on ne saurait que vous recommander est une nouvelle fois la représentation graphique ! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a90ed79",
   "metadata": {},
   "source": [
    "**Question 10:** Représentez graphiquement les valeurs prédites par rapport aux vraies valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91c2d74f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creer le scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Ajout des labels\n",
    "plt.xlabel('Vrai IMC')\n",
    "plt.ylabel('IMC prédit')\n",
    "\n",
    "# Ajout de la ligne à 45° comme référence\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Affichagedu graphique\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30b2699",
   "metadata": {},
   "source": [
    "**Question 11:** Commentez le graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2232687-d38e-42a8-8939-44a30dfc939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, RidgeCV, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce77b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORICAL_REGRESSION_IMPUT = [\"tage_PS_mois\", \"diplome_interv\", \"poids_perception\", \"menopause\", \"enceinte\", \"enceinte_12dermois\", \"atrav_interv\", \"trav_nuit_interv\", \"trav_nuit_2cl_interv\", \"RUC_4cl\", \"tps_travail_interv\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a7fdc",
   "metadata": {},
   "source": [
    "## 3. Méthodes de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97127511",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "013be7bb",
   "metadata": {},
   "source": [
    "Grâce à scikit learn, on va voir qu'il est très facile d'utiliser des méthodes de machine learning différentes maintenant qu'on a utilisé les fonctions de base lors de la régression linéaire. \n",
    "Nous allons maintenant essayer d'utiliser l'intégralité des variables qui nous sont disponibles dans la base de données initiale. Cela implique de se replonger un petit peu dans l'analyse des données. Nous avons vu précédemment que toutes les variables numériques ne pouvaient pas être imputées par la médiane et que dans certains cas une imputation par 0 est préférable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df9841",
   "metadata": {},
   "source": [
    "**Question 12:** Répertoriez l'ensemble des variables numériques à imputer par 0 dans une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aeaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\n",
    "    \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea2c97f8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL_0_IMPUT = [\n",
    "    \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8676c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "\n",
    "categorical_encoder = make_pipeline(minus_one_imputer)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac48219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfr['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preprocessor.fit_transform(X_train), columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c23778",
   "metadata": {},
   "source": [
    "On fait un grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_estimators\": [50, 100, 200],\n",
    "    \"regression__max_leaf_nodes\": [5, 10, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipe_rfr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e83fd45",
   "metadata": {},
   "source": [
    "Combien on va faire de simulation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24938648",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = pipe_gscv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_random_forest = pd.DataFrame(rfr.cv_results_)\n",
    "perf_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c10eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "# Line plot\n",
    "for max_leaf_nodes, group in perf_random_forest.groupby(\"param_regression__max_leaf_nodes\"):\n",
    "    x = group[\"param_regression__n_estimators\"]\n",
    "    y = group[\"mean_test_neg_root_mean_squared_error\"]\n",
    "    ax.scatter(x, y, label=f\"{max_leaf_nodes}\")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set(xlabel='Number of estimators', ylabel='Mean score on test sample')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0,\n",
    "           title='Depth of trees')\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e875cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b86642",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b39f83b",
   "metadata": {},
   "source": [
    "# 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "\n",
    "categorical_encoder = make_pipeline(minus_one_imputer)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7aca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__C\": np.logspace(-8, 8, 9, base=2), \n",
    "    \"regression__kernel\": [\"rbf\"],\n",
    "    \"regression__gamma\": [0.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1184d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_svr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b621bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f88985e9",
   "metadata": {},
   "source": [
    "# 5. XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53249e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0300ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2951b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1ad2743",
   "metadata": {},
   "source": [
    "# 6. KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e276b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a48a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knr['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_knr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b27c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb656017",
   "metadata": {},
   "source": [
    "# ANNEXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d25c8a-fa6a-44b9-80ea-cf3db328ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var = [\n",
    "\"NOIND\",\n",
    "\"imc\",\n",
    "\"sex_PS\",\n",
    "\"tage_PS\",\n",
    "\"tage_PS_mois\",\n",
    "\"diplome_interv\",\n",
    "\"etude_4cl_interv\",\n",
    "\"situ_prof_5cl_interv\",\n",
    "\"atrav_interv\",\n",
    "\"trav_nuit_interv\",\n",
    "\"trav_nuit_2cl_interv\",\n",
    "\"PCS_8cl_interv\",\n",
    "\"PCS_4cl_interv\",\n",
    "\"tps_travail_interv\",\n",
    "\"vacances_interv\",\n",
    "\"soins\",\n",
    "\"situ_fin_3cl\",\n",
    "\"revenu\",\n",
    "\"RUC_4cl\",\n",
    "\"nbpers\",\n",
    "\"nbadu\",\n",
    "\"nbenf\",\n",
    "\"situ_alim_statut\",\n",
    "\"IA_statut\",\n",
    "\"IA_score\",\n",
    "\"statnut\",\n",
    "\"maladie_allergie_alim\",\n",
    "\"intoall_confirm_med\",\n",
    "\"regime_vegetarien\",\n",
    "\"regime_allergie\",\n",
    "\"regime_maigrir_med\",\n",
    "\"regime_maigrir_choix\",\n",
    "\"regime_autre_med\",\n",
    "\"regime_poidsstable\",\n",
    "\"regime_forme\",\n",
    "\"regime_autreraison\",\n",
    "\"regime_non\",\n",
    "\"veget_viande\",\n",
    "\"veget_prodmer\",\n",
    "\"veget_prodlait\",\n",
    "\"veget_oeuf\",\n",
    "\"veget_miel\",\n",
    "\"veget_autre_alim\",\n",
    "\"allergie_laitvache\",\n",
    "\"allergie_prepainfsoja\",\n",
    "\"allergie_prepainfamande\",\n",
    "\"allergie_gluten\",\n",
    "\"allergie_farineble\",\n",
    "\"allergie_lupin\",\n",
    "\"allergie_arachide\",\n",
    "\"allergie_fruitcoque\",\n",
    "\"allergie_oeuf\",\n",
    "\"allergie_poisson\",\n",
    "\"allergie_crustace\",\n",
    "\"allergie_mollusque\",\n",
    "\"allergie_soja\",\n",
    "\"allergie_sesame\",\n",
    "\"allergie_moutarde\",\n",
    "\"allergie_sulfite\",\n",
    "\"allergie_celeri\",\n",
    "\"allergie_autres_fruitleg\",\n",
    "\"allergie_autresalim\",\n",
    "\"allergie_nondetermine\",\n",
    "\"allergie_fruits\",\n",
    "\"allergie_legumes\",\n",
    "\"regime_passe\",\n",
    "\"regime_nb_2dernann\",\n",
    "\"regime_nb_anter2dernann\",\n",
    "\"regime_type\" ,\n",
    "\"regime_duree_sem\",\n",
    "\"regime_duree_mois\",\n",
    "\"regime_duree_nsp\" ,\n",
    "\"poids_modif\",\n",
    "\"poids_modifalim\",\n",
    "\"poids_plusAP\",\n",
    "\"poids_medicaments\",\n",
    "\"poids_substituts\",\n",
    "\"poids_chirurgie\",\n",
    "\"poids_modifalim_laityaourt\",\n",
    "\"poids_modifalim_fromage\",\n",
    "\"poids_modifalim_mg\",\n",
    "\"poids_modifalim_fruit\",\n",
    "\"poids_modifalim_legume\",\n",
    "\"poids_modifalim_pdtfeculent\",\n",
    "\"poids_modifalim_pizza\",\n",
    "\"poids_modifalim_pain\",\n",
    "\"poids_modifalim_vrouge\",\n",
    "\"poids_modifalim_volaille\",\n",
    "\"poids_modifalim_oeuf\",\n",
    "\"poids_modifalim_gateau\",\n",
    "\"poids_modifalim_edulcorant\",\n",
    "\"poids_modifalim_pdtsalleges\",\n",
    "\"poids_modifalim_BS\",\n",
    "\"poids_modifalim_eau\",\n",
    "\"poids_modifalim_autre\",\n",
    "\"poids_perception\" ,\n",
    "\"nb_prise_10kg\",\n",
    "\"menopause\",\n",
    "\"enceinte\",\n",
    "\"enceinte_nbmois\",\n",
    "\"allaite\",\n",
    "\"allaite_nbsem\",\n",
    "\"enceinte_12dermois\",\n",
    "\"fume\",\n",
    "\"nb_cigarettes_jour\",\n",
    "\"nb_cigarettes_sem\",\n",
    "\"nb_cigarettes_nsp\",\n",
    "\"nb_cigares_jour\",\n",
    "\"nb_cigares_sem\",\n",
    "\"nb_cigares_nsp\",\n",
    "\"nb_pipes_jour\",\n",
    "\"nb_pipes_sem\",\n",
    "\"nb_pipes_nsp\",\n",
    "\"fume_age_debut\",\n",
    "\"fume_age_debut_nsp\",\n",
    "\"fume_age_arret\",\n",
    "\"fume_age_arret_nsp\",\n",
    "\"bmr_kcal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370cd24-1f44-475f-9156-323849c34743",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = desc_indiv[list_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27bbf3-e273-479a-8310-d13ee753c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna(subset=['imc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_parquet(\"description_individu_inca.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
