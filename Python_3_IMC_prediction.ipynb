{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beecbc70",
   "metadata": {},
   "source": [
    "# Partie 3 : Premiers pas vers les méthodes de ML supervisé en python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c721ac0",
   "metadata": {},
   "source": [
    "L'idée de cette partie est de tester différentes méthodes d'apprentissage statistique supervisées usuelles. Pour cela nous allons utiliser les données issues de la table de description des individus interviewés lors de l'enquête INCA 3 sur la consommation et les habitudes alimentaires des français.\n",
    "\n",
    "L'objectif consistera à prédire au mieux l'IMC d'un individu grâce aux diverses informations que nous détenons sur la personne. Contrairement à la partie 2 sur le clustering, il s'agit ici de d'apprentissage supervisé car nous avons en notre possessions des données labélisées. Parmi les méthodes d'apprentissages supervisé on distingue généralement deux grandes familles que sont la classification et la régression. Ici nous sommes confronté à un problème de régression puisque nous souhaitons prédire l'indice de masse corporelle exacte. Pour cela nous allons tester plusieurs méthodes différentes afin d'analyser lesquelles sont les plus efficaces sur les données que nous possédons.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c510f9",
   "metadata": {},
   "source": [
    "## 1. Prise en main des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65b5d4b1",
   "metadata": {},
   "source": [
    "Les données de l'enquête INCA3 sont disponibles sur *Data.gouv* à l'adresse suivante : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/. Cette table contient les données des questionnaires face-à-face relatifs aux volets « Socio-économique » et « Mesures anthropométriques » et des données des questionnaires auto-administrés relatifs aux volets « Etat de santé » et « Tabagisme ». \n",
    "\n",
    "Elle regroupe les informations suivantes : caractéristiques socio-démographiques de l’individu (ou de son représentant dans le cas des enfants), caractéristiques\n",
    "socio-démographiques de la personne de référence du foyer, niveau de vie du foyer, insécurité alimentaire, caractéristiques anthropométriques (poids, taille, indice\n",
    "de masse corporelle, statut pondéral) ; statut vis-à-vis d’allergies ou d’intolérances alimentaires, types de régimes alimentaires, types d’allergies ou d’intolérances\n",
    "alimentaires, régimes et histoire pondérale, statut vis-à-vis de la grossesse, de l’allaitement et de la ménopause (uniquement pour les femmes de 15 ans et plus),\n",
    "statut tabagique ; indicateurs de sous ou sur-déclaration en termes de consommations alimentaires.\n",
    "\n",
    "Nous avons préalablement selectionné un grand nombre de variables issues de cette base que nous avons ensuite enregistré dans un bucket s3. Vous pouvez les télécharger grâce à ma commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow import fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430475",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
    "\n",
    "bucket = \"projet-funathon\"\n",
    "path_data =  \"2023/sujet3/diffusion/description_individu_inca.parquet\"\n",
    "\n",
    "df = pq.ParquetDataset(f'{bucket}/{path_data}', filesystem=s3).read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63af787d",
   "metadata": {},
   "source": [
    "<i  class=\"fa fa-pencil\"></i> On peut tout d'abord remarquer que le jeu de données ne semble, a priori, pas idéal pour réaliser des méthodes de machine learning très complexes avec beaucoup de paramètres à estimer. Il arrive très souvent que des méthodes plus classiques soient aussi, voire plus, efficaces que les méthodes d'apprentissage statistique. Cependant ce jeu de données peut tout à fait être utilisé à des fins pédagogiques pour comprendre les principes généraux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20461c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ae1b18",
   "metadata": {},
   "source": [
    "Tout d'abord, commençons par définir quelques constantes qui nous seront utiles pour la suite, à savoir : \n",
    "- La variable d'intérêt que nous cherchons à prédire `TARGET_VARIABLE`\n",
    "- La variable correspondant au numéro d'individu `NOIND`\n",
    "- Un nombre arbitraire pour afin de simplifier la réplicabilité de nos expérimentations `SEED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afeedb4-ef62-4ca3-bde7-8c81e20c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VARIABLE=\"imc\"\n",
    "INDEX=\"NOIND\"\n",
    "SEED=2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e98384fd",
   "metadata": {},
   "source": [
    "**Question 1:** Comme souvent en science de la données, la partie la plus fastidieuse consiste à analyser les données à notre disposition. En vous aidant du dictionnaire accessible [ici](https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf) déterminer l'ensemble des variables numériques. Les autres variables seront considérées comme des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\n",
    "# REMPLIR ICI\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24b78538",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997bff29",
   "metadata": {},
   "source": [
    "Une pratique courante dans les projets de machine learning c'est de commencer par spécifier une fraction de notre jeu données comme un **échantillon de test**. Cet échantillon va être utilisé à la toute fin du projet de sorte à évaluer la performance de nos modèles sur des données qu'il n'aura jamais vu auparavant. L'échantillon restant, celui **d'entrainement**, est lui utilisé pour entrainer les algorithmes et comparer leurs performances. L'idée derrière cette division est de réduire le risque de sur-apprentissage de notre modèle et d'estimer une erreur de généralisation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935d6713",
   "metadata": {},
   "source": [
    "**Question 2:** Créer les variables `y` et `X` correspondant respectivement à la variable d'intérêt et aux différentes features de notre jeu de données. Diviser ensuite ce jeu de données en un échantillon de train et de test en utilisant la fonction `train_test_split` de [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Ne pas oublier de spécifier le `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Votre code ici"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a3dba9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_VARIABLE]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f174eaa4",
   "metadata": {},
   "source": [
    "## 2. Un modèle de régression linéaire simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d324b88",
   "metadata": {},
   "source": [
    "**Question 3:** Avant d'étudier différentes méthodes d'apprentissage statistique commençons par réaliser une régression linéaire classique. Pour cela, sélectionnez un petit nombre de variables $(< 10)$ qui vous semble pertinent pour prédire l'indice de masse corporelle d'une personne. Prenez à la fois des variables numériques et catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd56601",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_REGRESSION = [\n",
    "# A REMPLIR\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "# A REMPLIR\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5beca656",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "   # \"tage_PS_mois\",\n",
    "   # \"diplome_interv\",\n",
    "   # \"soins\",\n",
    "   # \"situ_fin_3cl\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "   # \"IA_statut\",\n",
    "   # \"statnut\",\n",
    "    \"poids_perception\" ,\n",
    "   # \"menopause\",\n",
    "    \"enceinte\",\n",
    "   # \"enceinte_12dermois\",\n",
    "   # 'etude_4cl_interv',\n",
    "   # 'situ_prof_5cl_interv',\n",
    "   # 'atrav_interv',\n",
    "   # 'trav_nuit_interv',\n",
    "   # 'trav_nuit_2cl_interv',\n",
    "   # 'PCS_8cl_interv',\n",
    "   # 'PCS_4cl_interv',\n",
    "   # 'tps_travail_interv',\n",
    "   # 'vacances_interv',\n",
    "   # 'RUC_4cl',\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "   # \"bmr_kcal\",\n",
    "   # 'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5068cd-d2f1-4edd-a5e3-2e131c7c39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train[FEATURES_REGRESSION]\n",
    "X_test_regression = X_test[FEATURES_REGRESSION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87529e-74d9-49e4-a1bf-ed597d3cf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a2ebf40",
   "metadata": {},
   "source": [
    "Ces informations nous indiquent qu'il y a plusieurs variables qui contiennent des valeurs manquantes. Afin de ne pas supprimer les lignes qui contiennent des valeurs manquantes nous allons tenter de les imputer. Plusieurs méthodes d'imputations peuvent être réalisées :\n",
    "\n",
    "- **Pour les variables numériques:** Il est courant de remplacer les variables manquantes par la moyenne ou la médiane de l'échantillon.\n",
    "- **Pour les variables catégorielles:** On peut remplacer les variables manquantes par le moden c'est à dire la valeur la plus fréquente dans l'échantillon ou en créant une nouvelle categorie reflétant une valeur manquante.\n",
    "\n",
    "D'autres méthodes qui requiert plus de modélisation sont également possible comme réaliser une régression afin de prédire les valeurs manquantes grâce aux autres features ou  utiliser un algorithme de K plus proche voisin. Toutes ces méthodes ont à la fois leurs avantages et leurs inconvénients, il est important de déterminer celle qui est la plus approprié pour le problème que vous souhaitez résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cf28e27",
   "metadata": {},
   "source": [
    "**Question 4:** Pour faire simple, nous allons remplacer les valeurs manquantes des variables numériques par la médiane et pour celles des variables catégorielles nous allons créer une nouvelle catégorie qui sera égale à $-1$. Ce dernier choix vous semble t-il approprié ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b0f2dc",
   "metadata": {},
   "source": [
    "**Question 5:** En vous aidant de la (documentation)[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute] de scikit learn , créez ces deux *Imputer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = # YOUR CODE\n",
    "median_imputer = # YOUR CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48cff599",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b74119c3",
   "metadata": {},
   "source": [
    "**Question 6:** Analysez les modalités de la variables `enceinte_nbmois`, une imputation par la moyenne vous semble-t-elle justifiée ? Si non, proposez une autre imputation. Existe t-il d'autres variables dans ce cas ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03399840",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pd.unique(X_train_regression[\"enceinte_nbmois\"])\n",
    "\n",
    "# Les valeurs manquantes correspondent plutôt à la modalité \"pas enceinte\", il est donc plus judicieux de remplacer les valeurs manquantes par 0.\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ded42c4",
   "metadata": {},
   "source": [
    "Une étape très importante lorsqu'on utilise des méthodes de machine learning est la standardisation des données afin de mettre toutes les variables à la même échelle. Lorsque les variables ont des échelles différentes, certaines peuvent dominer les autres dans le processus d'apprentissage, ce qui peut fausser les résultats. Plusieurs méthodes de standardisation peuvent être utilisées, les deux plus courantes sont: \n",
    "- la normalisation standard : $z = \\frac{x - \\bar{x}}{\\sigma}$\n",
    "- la normalisation 0-1 : $z = \\frac{x - min}{max - min}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aa43ba5",
   "metadata": {},
   "source": [
    "Nous pouvons donc créer une pipeline dans laquelle nos *features* passeront afin de subir diverses transformations. En l'occurence, nous souhaitons que nos les valeurs manquantes *features* soient imputées et que ces dernières soit standardisées. Pour cela nous pouvons utiliser la fonction `make_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc77a99",
   "metadata": {},
   "source": [
    "Une fois nos pipelines définies ils faut déterminer quelles *features* passent par quelles *pipelines*. Dans notre cas, on souhaite que les variables catégorielles passent par la pipeline spécifique à celles-ci et les variables numériques par la pipeline qui impute soit par la médiane, soit par 0. Pour cela on doit utiliser la fonction `ColumnTransformer`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc634d2",
   "metadata": {},
   "source": [
    "**Question 7:** En vous référant à la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) de la fonction, créez votre pipeline de preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    #YOUR CODE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ed35c11",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Click to see the answer </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89cd6074",
   "metadata": {},
   "source": [
    "On peut comparer notre jeu de données avant et après le passage dans notre pipeline. Vérifiez que les modifications ont bien été faites comme attendues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8232e344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerical_zero__enceinte_nbmois</th>\n",
       "      <th>numerical_zero__nb_prise_10kg</th>\n",
       "      <th>numerical_median__IA_score</th>\n",
       "      <th>categorical__sex_PS</th>\n",
       "      <th>categorical__tage_PS</th>\n",
       "      <th>categorical__revenu</th>\n",
       "      <th>categorical__situ_alim_statut</th>\n",
       "      <th>categorical__poids_perception</th>\n",
       "      <th>categorical__enceinte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-1.635165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>0.396878</td>\n",
       "      <td>-1.635165</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>1.514211</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-1.635165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>2.072877</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4672 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numerical_zero__enceinte_nbmois  numerical_zero__nb_prise_10kg  \\\n",
       "0                           -0.052955                      -0.720455   \n",
       "1                           -0.052955                      -0.720455   \n",
       "2                           -0.052955                      -0.720455   \n",
       "3                           -0.052955                       0.396878   \n",
       "4                           -0.052955                      -0.720455   \n",
       "...                               ...                            ...   \n",
       "4667                        -0.052955                      -0.720455   \n",
       "4668                        -0.052955                      -0.720455   \n",
       "4669                        -0.052955                       1.514211   \n",
       "4670                        -0.052955                      -0.720455   \n",
       "4671                        -0.052955                       2.072877   \n",
       "\n",
       "      numerical_median__IA_score  categorical__sex_PS  categorical__tage_PS  \\\n",
       "0                      -0.125994                  2.0                   9.0   \n",
       "1                      -1.635165                  1.0                   7.0   \n",
       "2                      -0.125994                  1.0                   6.0   \n",
       "3                      -1.635165                  2.0                   8.0   \n",
       "4                      -0.125994                  1.0                   4.0   \n",
       "...                          ...                  ...                   ...   \n",
       "4667                   -0.125994                  1.0                   4.0   \n",
       "4668                   -0.125994                  2.0                   5.0   \n",
       "4669                   -0.125994                  2.0                   9.0   \n",
       "4670                   -1.635165                  1.0                   3.0   \n",
       "4671                   -0.125994                  1.0                   7.0   \n",
       "\n",
       "      categorical__revenu  categorical__situ_alim_statut  \\\n",
       "0                    15.0                            1.0   \n",
       "1                     5.0                            2.0   \n",
       "2                    15.0                            1.0   \n",
       "3                     7.0                            1.0   \n",
       "4                    12.0                            1.0   \n",
       "...                   ...                            ...   \n",
       "4667                 15.0                            1.0   \n",
       "4668                  2.0                            1.0   \n",
       "4669                 14.0                            1.0   \n",
       "4670                  9.0                            2.0   \n",
       "4671                  9.0                            1.0   \n",
       "\n",
       "      categorical__poids_perception  categorical__enceinte  \n",
       "0                              -1.0                   -1.0  \n",
       "1                              -1.0                   -1.0  \n",
       "2                              -1.0                   -1.0  \n",
       "3                               2.0                    2.0  \n",
       "4                              -1.0                   -1.0  \n",
       "...                             ...                    ...  \n",
       "4667                           -1.0                   -1.0  \n",
       "4668                           -1.0                   -1.0  \n",
       "4669                            1.0                   -1.0  \n",
       "4670                           -1.0                   -1.0  \n",
       "4671                            1.0                   -1.0  \n",
       "\n",
       "[4672 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed = pd.DataFrame(preprocessor_regression.fit_transform(X_train_regression), columns=preprocessor_regression.get_feature_names_out())\n",
    "data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2232687-d38e-42a8-8939-44a30dfc939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, RidgeCV, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce77b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORICAL_REGRESSION_IMPUT = [\"tage_PS_mois\", \"diplome_interv\", \"poids_perception\", \"menopause\", \"enceinte\", \"enceinte_12dermois\", \"atrav_interv\", \"trav_nuit_interv\", \"trav_nuit_2cl_interv\", \"RUC_4cl\", \"tps_travail_interv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ff894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = data_preprocessed.corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor_regression), \n",
    "    ('regression', LinearRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pipe_lr.fit(X_train_regression, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97127511",
   "metadata": {},
   "source": [
    "# 3. Random forest Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5df9841",
   "metadata": {},
   "source": [
    "Comme enceinte nb mois, certains coonne une valeur manquante = 0 donc il ne faut pas prendre la médiane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8676c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "\n",
    "categorical_encoder = make_pipeline(minus_one_imputer)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac48219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfr['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preprocessor.fit_transform(X_train), columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c23778",
   "metadata": {},
   "source": [
    "On fait un grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_estimators\": [50, 100, 200],\n",
    "    \"regression__max_leaf_nodes\": [5, 10, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipe_rfr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e83fd45",
   "metadata": {},
   "source": [
    "Combien on va faire de simulation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24938648",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = pipe_gscv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_random_forest = pd.DataFrame(rfr.cv_results_)\n",
    "perf_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c10eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "# Line plot\n",
    "for max_leaf_nodes, group in perf_random_forest.groupby(\"param_regression__max_leaf_nodes\"):\n",
    "    x = group[\"param_regression__n_estimators\"]\n",
    "    y = group[\"mean_test_neg_root_mean_squared_error\"]\n",
    "    ax.scatter(x, y, label=f\"{max_leaf_nodes}\")\n",
    "\n",
    "# Set labels and title\n",
    "ax.set(xlabel='Number of estimators', ylabel='Mean score on test sample')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0,\n",
    "           title='Depth of trees')\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e875cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b86642",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b39f83b",
   "metadata": {},
   "source": [
    "# 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "\n",
    "categorical_encoder = make_pipeline(minus_one_imputer)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7aca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__C\": np.logspace(-8, 8, 9, base=2), \n",
    "    \"regression__kernel\": [\"rbf\"],\n",
    "    \"regression__gamma\": [0.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1184d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_svr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b621bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbaae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f88985e9",
   "metadata": {},
   "source": [
    "# 5. XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d9bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53249e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xgb['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0300ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2951b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1ad2743",
   "metadata": {},
   "source": [
    "# 6. KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e276b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a48a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knr['regression'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gscv = GridSearchCV(pipeline_knr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipe_gscv.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe_gscv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b27c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb656017",
   "metadata": {},
   "source": [
    "# ANNEXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d25c8a-fa6a-44b9-80ea-cf3db328ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var = [\n",
    "\"NOIND\",\n",
    "\"imc\",\n",
    "\"sex_PS\",\n",
    "\"tage_PS\",\n",
    "\"tage_PS_mois\",\n",
    "\"diplome_interv\",\n",
    "\"etude_4cl_interv\",\n",
    "\"situ_prof_5cl_interv\",\n",
    "\"atrav_interv\",\n",
    "\"trav_nuit_interv\",\n",
    "\"trav_nuit_2cl_interv\",\n",
    "\"PCS_8cl_interv\",\n",
    "\"PCS_4cl_interv\",\n",
    "\"tps_travail_interv\",\n",
    "\"vacances_interv\",\n",
    "\"soins\",\n",
    "\"situ_fin_3cl\",\n",
    "\"revenu\",\n",
    "\"RUC_4cl\",\n",
    "\"nbpers\",\n",
    "\"nbadu\",\n",
    "\"nbenf\",\n",
    "\"situ_alim_statut\",\n",
    "\"IA_statut\",\n",
    "\"IA_score\",\n",
    "\"statnut\",\n",
    "\"maladie_allergie_alim\",\n",
    "\"intoall_confirm_med\",\n",
    "\"regime_vegetarien\",\n",
    "\"regime_allergie\",\n",
    "\"regime_maigrir_med\",\n",
    "\"regime_maigrir_choix\",\n",
    "\"regime_autre_med\",\n",
    "\"regime_poidsstable\",\n",
    "\"regime_forme\",\n",
    "\"regime_autreraison\",\n",
    "\"regime_non\",\n",
    "\"veget_viande\",\n",
    "\"veget_prodmer\",\n",
    "\"veget_prodlait\",\n",
    "\"veget_oeuf\",\n",
    "\"veget_miel\",\n",
    "\"veget_autre_alim\",\n",
    "\"allergie_laitvache\",\n",
    "\"allergie_prepainfsoja\",\n",
    "\"allergie_prepainfamande\",\n",
    "\"allergie_gluten\",\n",
    "\"allergie_farineble\",\n",
    "\"allergie_lupin\",\n",
    "\"allergie_arachide\",\n",
    "\"allergie_fruitcoque\",\n",
    "\"allergie_oeuf\",\n",
    "\"allergie_poisson\",\n",
    "\"allergie_crustace\",\n",
    "\"allergie_mollusque\",\n",
    "\"allergie_soja\",\n",
    "\"allergie_sesame\",\n",
    "\"allergie_moutarde\",\n",
    "\"allergie_sulfite\",\n",
    "\"allergie_celeri\",\n",
    "\"allergie_autres_fruitleg\",\n",
    "\"allergie_autresalim\",\n",
    "\"allergie_nondetermine\",\n",
    "\"allergie_fruits\",\n",
    "\"allergie_legumes\",\n",
    "\"regime_passe\",\n",
    "\"regime_nb_2dernann\",\n",
    "\"regime_nb_anter2dernann\",\n",
    "\"regime_type\" ,\n",
    "\"regime_duree_sem\",\n",
    "\"regime_duree_mois\",\n",
    "\"regime_duree_nsp\" ,\n",
    "\"poids_modif\",\n",
    "\"poids_modifalim\",\n",
    "\"poids_plusAP\",\n",
    "\"poids_medicaments\",\n",
    "\"poids_substituts\",\n",
    "\"poids_chirurgie\",\n",
    "\"poids_modifalim_laityaourt\",\n",
    "\"poids_modifalim_fromage\",\n",
    "\"poids_modifalim_mg\",\n",
    "\"poids_modifalim_fruit\",\n",
    "\"poids_modifalim_legume\",\n",
    "\"poids_modifalim_pdtfeculent\",\n",
    "\"poids_modifalim_pizza\",\n",
    "\"poids_modifalim_pain\",\n",
    "\"poids_modifalim_vrouge\",\n",
    "\"poids_modifalim_volaille\",\n",
    "\"poids_modifalim_oeuf\",\n",
    "\"poids_modifalim_gateau\",\n",
    "\"poids_modifalim_edulcorant\",\n",
    "\"poids_modifalim_pdtsalleges\",\n",
    "\"poids_modifalim_BS\",\n",
    "\"poids_modifalim_eau\",\n",
    "\"poids_modifalim_autre\",\n",
    "\"poids_perception\" ,\n",
    "\"nb_prise_10kg\",\n",
    "\"menopause\",\n",
    "\"enceinte\",\n",
    "\"enceinte_nbmois\",\n",
    "\"allaite\",\n",
    "\"allaite_nbsem\",\n",
    "\"enceinte_12dermois\",\n",
    "\"fume\",\n",
    "\"nb_cigarettes_jour\",\n",
    "\"nb_cigarettes_sem\",\n",
    "\"nb_cigarettes_nsp\",\n",
    "\"nb_cigares_jour\",\n",
    "\"nb_cigares_sem\",\n",
    "\"nb_cigares_nsp\",\n",
    "\"nb_pipes_jour\",\n",
    "\"nb_pipes_sem\",\n",
    "\"nb_pipes_nsp\",\n",
    "\"fume_age_debut\",\n",
    "\"fume_age_debut_nsp\",\n",
    "\"fume_age_arret\",\n",
    "\"fume_age_arret_nsp\",\n",
    "\"bmr_kcal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370cd24-1f44-475f-9156-323849c34743",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = desc_indiv[list_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27bbf3-e273-479a-8310-d13ee753c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna(subset=['imc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_parquet(\"description_individu_inca.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
