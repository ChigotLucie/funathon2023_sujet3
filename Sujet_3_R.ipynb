{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fee4912-d12f-4b18-a9d9-f19a3704a9da",
   "metadata": {},
   "source": [
    "# Funathon 2023 - Sujet 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157edb9-8f45-4ad1-ab37-6c1a2e67a7c5",
   "metadata": {},
   "source": [
    "Responsables :\n",
    "- Julie Sixou, D2E\n",
    "- Antoine Palazzolo, SSP Lab\n",
    "- Thomas Faria, SSP Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3a94a-ef0d-4501-9228-220d31f3ceb6",
   "metadata": {},
   "source": [
    "# Habitudes alimentaires à partir des données INCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8a7a3-50dc-4e38-9205-420b9cab1f55",
   "metadata": {},
   "source": [
    "## Avant de commencer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c84d3c-2058-4266-bf2f-d52b4a282e6f",
   "metadata": {},
   "source": [
    "Ce sujet est disponible dans 2 langages : R et Python.\n",
    "Ce notebook correspond à la version R, qui est la plus réduite des deux. En effet, la partie 3 sur les premiers pas en Machine Learning est spécifique à Python.\n",
    "\n",
    "Il s'agit là principalement d'une initiation à l'analyse de données et à la data visualization, à travers l'étude des données de consommations et habitudes alimentaires de l'[étude INCA 3](https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/).\n",
    "Le sujet est constituée de 3 parties distinctes et indépendantes :\n",
    "- Analyse exploratoire des données et visualisations\n",
    "- Clustering d'individus : ACP, K-moyennes, Clustering Ascendant Hiérarchique\n",
    "- __Absente du sujet en R__ : _Prédiction de l'IMC : premiers pas vers les méthodes de ML supervisé_\n",
    "\n",
    "Il est également possible de ne faire qu'une ou deux parties du sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbe276-e2db-471a-931c-be05efea1069",
   "metadata": {},
   "source": [
    "Si jamais vous n'êtes pas familiers avec R, nous ne saurions que trop vous recommander de jeter un oeil aux ressources suivantes :\n",
    "- Débuter avec R : https://www.utilitr.org/\n",
    "- Bonnes pratiques en R : https://www.pratiques.utilitr.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e875b-59ac-48cb-8629-e50f7c3af232",
   "metadata": {},
   "source": [
    "Pour en savoir plus sur les données utilisées pour ce sujet et sur le contexte de l'étude : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/\n",
    "\n",
    "Pour lire la documentation associée aux données : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc0ae1-3e63-4792-8f12-91dd0ef12206",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccb064-1f6b-4152-852c-729209734fc7",
   "metadata": {},
   "source": [
    "Exécutez à présent la cellule ci-dessous pour installer les packages nécessaires au sujet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea2450c2-3fb1-4aaf-91ef-30fbe145eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lecture du fichier requirements.txt\n",
    "requirements <- readLines(\"requirements_R.txt\")\n",
    "\n",
    "# Installation des packages\n",
    "for (package in requirements) {\n",
    "  install.packages(package)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd2bb9-d628-436b-a154-c184296c4252",
   "metadata": {},
   "source": [
    "Exécutez également les cellules ci-dessous pour importer l'ensemble des jeux de données nécessaires à l'étude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35bad17b-338a-4608-8701-5bea6c103aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(aws.s3)\n",
    "library(readr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1e139-05ca-4d27-8965-ee9659770945",
   "metadata": {},
   "source": [
    "#### Imports des données avec s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b31fc-f676-489f-93c3-4adce67aacc3",
   "metadata": {},
   "source": [
    "A favoriser, en utilisant les données déjà importées sur le Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ede8e94d-8a1d-4738-a4f1-21ddb271009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket <- \"projet-funathon\"\n",
    "path_data <- \"2023/sujet3/diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0419eb87-e41f-41ee-962d-a69f0f6b354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mOne or more parsing issues, call `problems()` on your data frame for details,\n",
      "e.g.:\n",
      "  dat <- vroom(...)\n",
      "  problems(dat)”\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m5855\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m185\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \";\"\n",
      "\u001b[31mchr\u001b[39m   (7): zae, regime_raisonmed_libelle, allergie_fruitcoque_libelle, aller...\n",
      "\u001b[32mdbl\u001b[39m (176): NOMEN, NOIND, ech, enf_allaite, pop1, pop2, pop3, pond_indiv_adu_...\n",
      "\u001b[33mlgl\u001b[39m   (2): veget_autre_alim_libelle, allaite_nbsem\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mOne or more parsing issues, call `problems()` on your data frame for details,\n",
      "e.g.:\n",
      "  dat <- vroom(...)\n",
      "  problems(dat)”\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m4372\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m389\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \";\"\n",
      "\u001b[31mchr\u001b[39m  (35): POPULATION, lait_plusvt_boisson_veg_libelle, lait_plusvt_autre_li...\n",
      "\u001b[32mdbl\u001b[39m (342): NOIND, periode_reference, repasenfantmidi_vous, repasenfantmidi_a...\n",
      "\u001b[33mlgl\u001b[39m  (12): repasenfantmidi_autre_libelle, lait_plusvt_li_autr_anim_libelle, ...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mOne or more parsing issues, call `problems()` on your data frame for details,\n",
      "e.g.:\n",
      "  dat <- vroom(...)\n",
      "  problems(dat)”\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m4725\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m93\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \";\"\n",
      "\u001b[31mchr\u001b[39m  (1): POPULATION\n",
      "\u001b[32mdbl\u001b[39m (89): NOIND, transport_personnel, transport_ecole, tv_score, tv_duree, j...\n",
      "\u001b[33mlgl\u001b[39m  (3): activite_escrime_score, activite_alpinisme_score, activite_hockey_...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m4339\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m384\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \";\"\n",
      "\u001b[31mchr\u001b[39m   (1): POPULATION\n",
      "\u001b[32mdbl\u001b[39m (383): NOIND, PC_pain_ON, PC_pain_freq_M, PC_paincomplet_ON, PC_paincomp...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "description_indiv <- s3read_using(read_delim, object = paste(path_data, \"description-indiv.csv\", sep=\"/\"), bucket = bucket, opts = list('region'=''))\n",
    "habitudes_indiv <- s3read_using(read_delim, object = paste(path_data, \"habitudes-indiv.csv\", sep=\"/\"), bucket = bucket, opts = list('region'=''))\n",
    "actphys_sedent <- s3read_using(read_delim, object = paste(path_data, \"actphys-sedent.csv\", sep=\"/\"), bucket = bucket, opts = list('region'=''))\n",
    "fpq <- s3read_using(read_delim, object = paste(path_data, \"fpq.csv\", sep=\"/\"), bucket = bucket, opts = list('region'=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a514efc-732c-4aca-8c29-eacdcdbe55c4",
   "metadata": {},
   "source": [
    "#### Imports des données depuis data.gouv.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd17192-125e-429c-bd50-96ddc6c2da5e",
   "metadata": {},
   "source": [
    "Eviter cette option pour ne pas surcharger le SSP Cloud si trop de participants font des téléchargements en même temps. A n'utiliser que si impossibilité d'utiliser le Datalab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd4507-22d0-4a28-a2ef-1ddd440a676a",
   "metadata": {},
   "source": [
    "```r\n",
    "# Lecture des fichiers CSV\n",
    "description_indiv <- read_delim(\"https://www.data.gouv.fr/fr/datasets/r/f982ee4a-b2db-4608-ab95-bfe51dfc4897\", delim=\";\")\n",
    "habitudes_indiv <- read_delim(\"https://www.data.gouv.fr/fr/datasets/r/099351b9-e32e-4e38-8f23-dec21fd07c71\", delim=\";\")\n",
    "actphys_sedent <- read_delim(\"https://www.data.gouv.fr/fr/datasets/r/e9a34b81-2105-4d82-a023-c14947fb2b2c\", delim=\";\")\n",
    "fpq <- read_delim(\"https://www.data.gouv.fr/fr/datasets/r/32e79499-9897-423b-acd6-143121340f86\", delim=\";\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b023787-27db-4ad6-8cf6-f2d7cd3e443d",
   "metadata": {},
   "source": [
    "## Partie 1 : Analyse exploratoire des données et visualisations\n",
    "\n",
    "Premier point de contact : Julie Sixou\n",
    "\n",
    "Boîte à outils de ce qu'il est possible de faire avec ```dplyr``` et ```ggplot2```\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9e446-8890-4641-bb89-f3a89e7f0479",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c505b8b-a7c4-4f64-ac13-ee90f4a8dc13",
   "metadata": {},
   "source": [
    "Explorons la base de données INCA3 : dans cette partie, nous allons vous montrer comment produire des graphes et statistiques univariées et bivariées.\n",
    "\n",
    "Le dictionnaire des variables et des modalités peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da0c89-a253-4bee-b145-d33c9df21697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de Cartiflette pour la partie \"Cartographie\"\n",
    "!pip install git+https://github.com/inseefrlab/cartogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133fdab-6cc4-4b35-8d98-1aa394c8416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "\n",
    "import cartiflette.s3\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "\n",
    "from pyarrow import fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c3b92-7832-4d9a-8f11-0a8fa644c0d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Statistiques univariées avec la table _description_indiv_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba045c-d3eb-4f73-a071-021bd08ed9bd",
   "metadata": {},
   "source": [
    "Quelques exemples de ce qu'il est possible de faire avec ```matplotlib.pyplot``` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566ec9a-93b2-4480-831f-ec9bbc1a994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme des IMC\n",
    "\n",
    "description_indiv[\"imc\"].hist(\n",
    "    bins=50,  # Nombre de barres de l'histogramme\n",
    "    range=(0, 100),  # Plage des valeurs affichées sur l'axe x\n",
    "    color='skyblue',  # Couleur des barres de l'histogramme\n",
    "    edgecolor='black',  # Couleur des bords des barres\n",
    "    alpha=0.7  # Transparence des barres\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455a606-72ba-4778-b488-22135e01647c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogramme des niveaux de diplôme\n",
    "\n",
    "description_indiv[\"diplome_interv\"].hist(\n",
    "    color=\"red\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# Cette fois on ajoute une légende et un titre\n",
    "plt.title(\"Histogramme des niveaux de diplôme\")\n",
    "plt.xlabel(\"Code du niveau de diplôme\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a54e5-3c12-4450-9232-f7f6d3cbaed0",
   "metadata": {},
   "source": [
    "Recodons la variable des niveaux de diplôme pour mieux comprendre le graphe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a3999-1184-4c84-b052-8483983d04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodage des niveaux de diplôme\n",
    "\n",
    "dico_libelle_diplome = {1: \"Aucun diplôme, n'a jamais été scolarisé\", \n",
    "                        2: \"Aucun diplôme, scolarité s'est arrêtée à l'école primaire\", \n",
    "                        3: \"Aucun diplôme, scolarité s'est arrêtée au collège\",\n",
    "                       4:\"Aucun diplôme, scolarité s'est arrêtée au delà du collège\",\n",
    "                       5:\"Aucun diplôme, sans précision\",\n",
    "                       6:\"CEP\",\n",
    "                       7:\"CAP, BEP, BEPC, brevet élémentaire, brevet de compagnon\",\n",
    "                       8:\"Baccalauréat technologique ou professionnel, Brevet professionnel ou de technicien, BEA, BEC, BEI, BEH, capacité en droit \",\n",
    "                       9:\"Baccalauréat général\",\n",
    "                       10:\"Diplôme de 1er cycle universitaire (Bac +3, licence), BTS, DUT, DEST, DEUG, diplôme des professions sociales ou de la santé, d'infirmier\",\n",
    "                       11:\"Diplôme de 2ème cycle universitaire (Bac+4, Bac+5), Master, Maîtrise, diplôme d'ingénieur, d'une grande école\",\n",
    "                       12:\"Diplôme de 3ème cycle universitaire (>Bac+5, doctorat), diplôme de vétérinaire, médecin, pharmacien\",\n",
    "                       13:\"Refus\",\n",
    "                       14:\"Ne sait pas\"}\n",
    "\n",
    "description_indiv['categorie_diplome'] = description_indiv['diplome_interv'].replace(dico_libelle_diplome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b997b6-c229-4c6f-b2a0-92bbe14c2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau des fréquences de chaque catégorie de diplome\n",
    "counts_diplome = description_indiv['categorie_diplome'].value_counts()\n",
    "\n",
    "# Graphique en barres horizontales\n",
    "counts_diplome.plot(kind='barh',\n",
    "                   color=\"red\",\n",
    "                   edgecolor=\"black\",\n",
    "                   alpha=0.7)\n",
    "\n",
    "\n",
    "plt.title(\"Histogramme des niveaux de diplôme\")\n",
    "plt.xlabel(\"Libelle du niveau de diplôme\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e0a4b-77ed-4e22-8ea9-214187de838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme type d'agglomération\n",
    "\n",
    "dico_libelle_agglo = {1:\"Rural\",\n",
    "                     2:\"2000 - 19 999 hab\",\n",
    "                     3:\"20 000 - 99 999 hab\",\n",
    "                     4:\"+ 100 000 hab\",\n",
    "                     5:\"Paris\"}\n",
    "\n",
    "description_indiv['categorie_agglo'] = description_indiv['agglo_5cl'].replace(dico_libelle_agglo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f33a4-1c3f-4885-9b93-a01ba81b8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_agglo = description_indiv['categorie_agglo'].value_counts()\n",
    "\n",
    "# Générer le graphique en barres horizontales\n",
    "counts_agglo.plot(kind='barh',\n",
    "                   color=\"green\",\n",
    "                   edgecolor=\"black\",\n",
    "                   alpha=0.7)\n",
    "\n",
    "\n",
    "plt.title(\"Histogramme des types d'agglomération\")\n",
    "plt.xlabel(\"Type d'agglomération\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eebd6b-9344-4bc6-a915-a0710e37d9a5",
   "metadata": {},
   "source": [
    "Faire pareil pour les tranches de revenu : histogramme de la variable **RUC_4cl** qui donne le revenu mensuel total du foyer par unité de consommation (UC) en 4 classes. Les modalités de la variable sont les suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c44f2-5112-432e-9c0d-589d0d88cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niveau de vie\n",
    "\n",
    "dico_RUC = {1:\"<900 €/mois/UC\",\n",
    "            2:\"[900-1 340[ €/mois/UC\",\n",
    "            3:\"[1 340-1 850[ €/mois/U\",\n",
    "            4:\">=1 850 €/mois/UC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67da53f-13a5-4be7-9f5b-9baa3744d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a91493-8198-4f0a-a898-611606de659b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Statistiques bivariées avec les tables _description_indiv_ et _habitudes_indiv_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79695f8-5932-4b1d-ba18-0ad2c228cf71",
   "metadata": {},
   "source": [
    "Quelques exemples de ce qu'il est possible de faire avec ```matplotlib.pyplot``` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118925dd-48c3-4a49-b799-d8625dd516f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imc moyen par niveau de diplôme\n",
    "\n",
    "imc_par_diplome = description_indiv.groupby('categorie_diplome')['imc'].mean().sort_values(ascending=False)\n",
    "imc_par_diplome.plot(kind='barh',\n",
    "                    color=\"grey\",\n",
    "                    alpha=0.7)\n",
    "\n",
    "plt.title('Imc moyen par niveau de diplôme')\n",
    "plt.xlabel('Imc moyen')\n",
    "plt.ylabel('Niveau de diplôme')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d36c6-12a4-4aa4-aff3-0e0791273085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoproduction par type d'agglomération\n",
    "\n",
    "description_x_habitudes = pd.merge(description_indiv, habitudes_indiv,on=\"NOIND\")\n",
    "autoprod_par_agglo = description_x_habitudes.groupby('categorie_agglo')['autoproduction'].mean().sort_values(ascending=False)\n",
    "autoprod_par_agglo.plot(kind='barh',\n",
    "                    color=\"darkgreen\",\n",
    "                    alpha=0.7)\n",
    "\n",
    "plt.title(\"Part d'autoproduction par type d'agglomération\")\n",
    "plt.xlabel(\"Part d'autoproduction\")\n",
    "plt.ylabel(\"Type d'agglomération\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1c608-37e5-41b2-a0f3-52c767c9d2cc",
   "metadata": {},
   "source": [
    "Représenter le croisement entre le score d'insécurité d'alimentaire (**IA_score**, on peut en faire la moyenne) et les tranches de revenu (par exemple, **RUC_4cl** qu'on a recodée précédemment, ou **revenu** qui donne le revenu disponible codé en plus de classes.)\n",
    "\n",
    "Le dictionnaire des variables et des modalités peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a18bc-0350-478d-9f93-3d15e8baa155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score d'IA par tranche de revenu\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b1d4-ff77-4e61-a0fe-86f0565c86e5",
   "metadata": {},
   "source": [
    "Finalement, on se rend compte que la base est très riche et contient beaucoup de variables : beaucoup d'entre elles sont quantitatives, et on peut s'amuser à représenter leurs relations de corrélations en même temps dans une matrice de corrélation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cc5f6-6bba-484c-a45b-e232e64016d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "\n",
    "df_num = description_x_habitudes.select_dtypes(include=['int', 'float'])\n",
    "df_num=df_num[[\"revenu\",\"IA_score\",\"imc\",\"regime_vegetarien\",\"poidsmax\",\"fume\",\"source_famille\",\"jardin_potager\",\"autoconsommation\",\"consommation_bio\"]]\n",
    "matrice_correlation = df_num.corr()\n",
    "matrice_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f548d-e186-4e74-90f0-dee4111ca50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrice_correlation, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d47dfb-434b-48e8-829e-56063e29af54",
   "metadata": {},
   "source": [
    "A vous d'ajouter les variables qui vous intéressent et à multiplier les visualisations !\n",
    "Les plus beaux graphes seront partagés à l'issue du funathon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f3843-855f-4fa4-8f76-171b81930a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd7c0-7459-4474-a8c0-4977f185324b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Cartographie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578ecff-28da-4834-a461-71d9682f4eff",
   "metadata": {},
   "source": [
    "Pour la cartographie, on a besoin de fonds de carte. Ce sont des bases d'objets vectoriels. Par exemple, pour une carte de France par région, on aura une ligne par région avec un attribut géographique renseignant les coordonnées du vecteur (ou polygone). Le package **cartiflette** nous permet de les télécharger directement et facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1f720-16fc-4565-b98d-fd688614d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = cartiflette.s3.download_vectorfile_url_all(\n",
    "    crs = 4326,\n",
    "    values = \"metropole\",\n",
    "    borders=\"REGION\", # notre unité géographique\n",
    "    vectorfile_format=\"topojson\",\n",
    "    filter_by=\"FRANCE_ENTIERE\", # le champ qui nous intéresse\n",
    "    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n",
    "    year=2022)\n",
    "ax = region.plot()\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94a5ca-5805-4928-8113-ccca4a8be8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaece957-d5e8-40e4-9fc8-b5fb24505565",
   "metadata": {},
   "source": [
    "On va s'intéresser aux fréquences de consommation de certains aliments, présentes dans la table fpq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7064d-f2c5-4e96-b0f0-f0e0ed9c8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_x_fpq = pd.merge(description_indiv,fpq,on=\"NOIND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ebb09-99e8-4bde-9014-909c8954046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodage de la variable région pour avoir les mêmes noms que dans notre fond de carte (qu'on vient de télécharger avec cartiflette)\n",
    "\n",
    "dico_libelle_region = {1:\"ILE-DE-FRANCE\",\n",
    "                      2:\"NORMANDIE\",\n",
    "                      3:\"CENTRE-VAL DE LOIRE\",\n",
    "                      4:\"PAYS DE LA LOIRE\",\n",
    "                      5:\"BRETAGNE\",\n",
    "                      6:\"HAUTS-DE-FRANCE\",\n",
    "                      7:\"GRAND EST\",\n",
    "                      8:\"BOURGOGNE-FRANCHE-COMTE\",\n",
    "                      9:\"AUVERGNE-RHONE-ALPES\",\n",
    "                      10:\"PROVENCE-ALPES-COTE D'AZUR\",\n",
    "                      11:\"OCCITANIE\",\n",
    "                      12:\"NOUVELLE-AQUITAINE\"}\n",
    "\n",
    "description_x_fpq[\"region_recode\"]=description_x_fpq['region_adm_12cl'].replace(dico_libelle_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23998dd9-4c75-4744-8c28-2ffa3ebc51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable à représenter géographiquement : nombre de bière consommées par mois. \n",
    "\n",
    "biere_par_region = description_x_fpq.groupby('region_recode')['BA_biere_freq_M'].mean()\n",
    "biere_par_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbba85-23dd-484c-8eaf-7ba9a979ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un petit tableau avec nos régions et leurs attributs géographiques, \n",
    "# et surtout la variable qu'on vient de calculer (c'est-à-dire le nombre de bières consommées par mois par région en moyenne)\n",
    "\n",
    "region_inca=pd.merge(region,biere_par_region,left_on=\"NOM_M\",right_on=\"region_recode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5224851-7086-4838-b1fe-9f0af1a43376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez une figure et des axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Dessinez la carte choroplèthe\n",
    "region_inca.plot(column='BA_biere_freq_M', cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "# Ajoutez une légende\n",
    "sm = plt.cm.ScalarMappable(cmap='YlOrRd', norm=plt.Normalize(vmin=region_inca['BA_biere_freq_M'].min(), vmax=region_inca['BA_biere_freq_M'].max()))\n",
    "plt.colorbar(sm, ax=ax)\n",
    "plt.title(\"Nombre de bières consommées par mois en moyenne par région\")\n",
    "\n",
    "# Affichez le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b9956-0a0d-456b-8693-6a4c4c0c8b12",
   "metadata": {},
   "source": [
    "Maintenant, créez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libellés; Les fréquences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces dernières valent 1 si le produit est consommé et 0 sinon). \n",
    "\n",
    "Par exemple, on peut choisir parmi les variables dans : ```fpq.columns.tolist()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57d344-3e83-4b4b-a5ca-12faf0a10e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f456cf-c7ca-4b80-885d-8b31fe5073e3",
   "metadata": {},
   "source": [
    "## Partie 2 : Clustering d'individus\n",
    "\n",
    "Premier point de contact : Antoine Palazzolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a2760-a941-4f12-84e3-278180730cf1",
   "metadata": {},
   "source": [
    "Lorsque l'on pense au Machine Learning, les premiers exemples qui viennent en tête sont souvent des problèmes de régression ou bien de classification.\n",
    "Ces cas d'usage font partie d'une branche du ML appelée _apprentissage supervisé_, qui requiert notamment d'avoir des données labellisées permettant aux diverses méthodes utilisées de comprendre la relation entre un ensemble de variables explicatives et une variable à prédire.\n",
    "\n",
    "_L'apprentissage non supervisé_ est une autre branche du ML qui ne consiste cette fois plus à prédire une variable donnée à partir de données labellisées.\n",
    "Au coeur de l'apprentissage non supervisé on trouve notamment le __clustering__.\n",
    "Cette fois-ci, le but est de créer à partir d'une population donnée un ensemble de clusters (ou paquets) d'individus regroupés par similarité, en utilisant de façon automatiques les caractéristiques les plus discriminantes de notre population. Ce sera peut-être plus clair avec quelques exemples et applications :\n",
    "- Une enseigne de retail possède une centaine de magasins en France et souhaite regrouper ces derniers en une poignée de groupes qu'elle pourra approvisionner de la même façon. Chaque groupe devra regrouper des magasins ayant des performances similaires et une clientèle proche. C'est un problème de clustering.\n",
    "- A partir d'une base de données regroupant les thèmes de prédilection de centaines de journalistes (ou bien leurs références), on souhaite regrouper ces mêmes journalistes en quelques catégories au sein desquelles chaque individu aura une orientation politique proche de celles des autres.\n",
    "- En fonction des caractéristiques physiques d'espèces animales ou végétales, on souhaite regrouper ces espèces en un plus petit nombre de groupes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e57398-8acd-4680-8fa5-ea5d712b1921",
   "metadata": {},
   "source": [
    "Il existe plusieurs méthodes pour faire du clustering, les deux plus connues étant :\n",
    "- Les [K-Moyennes](https://fr.wikipedia.org/wiki/K-moyennes) (ou K-Means), méthode la plus connue, basée sur l'utilisation de centroïdes itérés\n",
    "- Le [Clustering Ascendant Hiérarchique](https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique) (CAH), basé sur des regroupements en groupes de plus en plus grands, donnant par exemple lieu à des visualisations sous forme de dendrogrammes (ressemblant aux arbres phylogénétiques de vos cours de SVT au lycée)\n",
    "\n",
    "Nous allons mettre en pratique ces deux méthodes dans ce sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73323a-0153-41b6-9017-06b3a560e6c7",
   "metadata": {},
   "source": [
    "Une fois nos clusterings effectués, l'un des enjeux est ensuite aussi de pouvoir interpréter ces derniers :\n",
    "- Quelles sont les caractéristiques les plus discriminantes dans la constitution des groupes ?\n",
    "- Les clusters générés font-ils bien sens ? Que peut-on dire de ces groupes ?\n",
    "- Quelles méthodes de visualisation sont les plus adaptées ?\n",
    "\n",
    "Pour répondre à ces questions, un des outils principaux que nous pouvons utiliser est l'[Analyse en Composantes Principales](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales) (ACP), qui à partir de l'ensemble initial des colonnes en crée un ensemble de taille réduite qui maximise la discrimination des données les unes par rapport aux autres via ces nouvelles colonnes.\n",
    "En réduisant la dimension à moins de 3, on peut ainsi représenter graphiquement les données de façon plus claire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917d36-8696-4440-9b55-9f61725ea2f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Preprocessing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049f261-da0b-4ee8-b13a-1d56de6a4096",
   "metadata": {},
   "source": [
    "Pour cette étude nous allons commencer par la table des habitudes individuelles.\n",
    "Cette table contient les données des questionnaires auto-administrés relatifs aux volets « Habitudes alimentaires » et « Origine des aliments ».\n",
    "\n",
    "Elle regroupe les informations suivantes : lieux et occasions de consommation, consommations hors-foyer et entre les repas, préférences alimentaires, présence de sel/beurre/sauce sur la table au moment des repas, lecture des étiquettes, sources d’informations en alimentation, consommation de denrées animales crues et des croûtes de fromage, préparation des fruits et légumes crus, spécificités de l’alimentation des enfants de 0 à 35 mois (ex : allaitement (exclusif ou partiel), type de laits consommés, diversification alimentaire, matériaux des biberons et des tétines, préparation, stockage et conservation des biberons de lait, mode de chauffage des laits et contenants utilisés), autoconsommation et utilisation de produits phytosanitaires au potager, consommation d’aliments issus de l’agriculture biologique et cuisson des aliments au barbecue.\n",
    "\n",
    "Une fois le sujet terminé, vous pourrez si vous le souhaitez reproduire cette partie avec d'autres des tables à disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787ea21-06f5-464e-b45d-8ea6a4f70d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0794e5-da86-449b-a085-bdba43fa1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7869779e-c56a-41b8-b79a-a789137cb453",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etape 1 : Analyse exploratoire & sélection de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435dce15-ae58-44fb-9243-5a71a7c44c12",
   "metadata": {},
   "source": [
    "Regardons déjà à quoi ressemblent nos données en pratique. En utilisant Pandas, pouvez-vous dire :\n",
    "- Combien y a-t-il d'individus et de variables ?\n",
    "- Combien de variables présentent des valeurs vides ? En quelle proportion ?\n",
    "- Y a-t-il des variables qui ont la même valeur pour tous les individus ? Seront-elles utiles pour la discrimination des observations dans le clustering ?\n",
    "- Y a-t-il des variables qui n'ont pas de sens pour la caractérisation d'un groupe ? Cela comprend par exemple les identifiants.\n",
    "- Quels sont les types des variables ? Combien de variables non-numériques ? En pratique nous allons ici nous focaliser uniquement sur les données numériques de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93578fa3-f1db-4c5e-9cfa-a66ff7d33d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer !\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c87c7-fd5e-4ed9-aea4-e231b8ef9f76",
   "metadata": {},
   "source": [
    "A partir des analyses que vous venez de réaliser, vous devriez avoir une meilleure idée de quoi garder dans la table pour appliquer les méthodes de clustering. Créez donc ```habitudes_indiv_clustering_1``` à partir de ```habitudes_indiv``` en retirant toutes les colonnes gênantes ou inutiles :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd79ab0-a795-4f1b-9fa4-02fdd02e166a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Si besoin, dérouler pour révéler les indications plus détaillées :</summary>\n",
    "<br>\n",
    "\n",
    "Il vous faudra donc, a minima :\n",
    "- Retirer les colonnes d'identifiants\n",
    "- Retirer les colonnes vides\n",
    "- Conserver uniquement les colonnes numériques\n",
    "\n",
    "Pour aller plus loin, retirez les colonnes à moins de 2 valeurs distinctes.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e350037-bcdd-4618-a217-66f25a970d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_1 = pd.DataFrame() # TODO\n",
    "\n",
    "habitudes_indiv_clustering_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591321f-ef34-4957-8f78-c8290c1f7641",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Sélectionner les caractéristiques pour le clustering\n",
    "\n",
    "habitudes_indiv_clustering_1 = habitudes_indiv.drop(\n",
    "    ['POPULATION', 'NOIND', 'periode_reference'],  # Identifiants\n",
    "    axis=1\n",
    ").dropna(\n",
    "    axis=1, how='all'  # Colonnes vides\n",
    ").select_dtypes(\n",
    "    include=np.number  # Colonnes numériques à garder\n",
    ")\n",
    "\n",
    "habitudes_indiv_clustering_1 = habitudes_indiv_clustering_1.loc[\n",
    "    :, habitudes_indiv_clustering_1.nunique() > 1\n",
    "]  # On retire les colonnes avec moins de 2 valeurs distinctes\n",
    "\n",
    "habitudes_indiv_clustering_1.shape\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019df24-d84e-487d-b086-669ac6d538c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etape 2 : Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ae675-56f4-4bb9-8e8b-3c3c68ce3af0",
   "metadata": {},
   "source": [
    "Comme vous l'avez peut-être vu, si l'on cherche à retirer toutes les lignes ou colonnes avec au moins une valeur manquante, il ne reste plus grand-chose à la table...\n",
    "Nous allons donc les garder, d'autant plus que cela ne les empêche pas de contenir de l'information importante.\n",
    "\n",
    "Dans ce cas comment traiter les NaNs ?\n",
    "Il existe une méthode pour les remplacer par une valeur numérique, il s'agit de l'__[imputation](https://fr.wikipedia.org/wiki/Imputation_(statistique))__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50fa3e6-c22b-45ca-bd9f-20fe2c0146b6",
   "metadata": {},
   "source": [
    "Plusieurs méthodes d'imputation existent : remplacer les valeurs manquantes par la moyenne de la colonne, par une valeur issue de régression linéaire, de régression stochastique, etc.\n",
    "\n",
    "Dans notre cas particulier, la plupart des variables sont binaires, des réponses Oui/Non à une question.\n",
    "Une méthode que nous pouvons donc utiliser (mais d'autres marcheraient très bien aussi) est l'imputation par la valeur la plus fréquente de la colonne.\n",
    "\n",
    "En termes d'interprétation, cela revient à simplifier le problème en considérant que les non-répondants auraient répondu la même chose que la majorité des répondants, quitte à ce que cela mène à de possibles erreurs.\n",
    "Par exemple, les répondants \"Homme\" ont peu de chances de répondre \"Oui\" à l'allaitement, mais c'est une solution qui fonctionne tout de même en général très bien.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee550d-573c-43b1-aa6d-00829fbc94e2",
   "metadata": {},
   "source": [
    "A présent, appliquez cette stratégie d'imputation sur la table ```habitudes_indiv_clustering_1``` pour donner naissance à ```habitudes_indiv_clustering_2```. On demandera à ce que la table nouvellement créée soit sous la forme d'un array numpy, pour faciliter la suite des opérations.\n",
    "\n",
    "Vous avez le droit d'importer et utiliser la fonction ```SimpleImputer``` du package ```sklearn.impute```, dont l'output est déjà bien sous un format numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bd13b-12d2-464a-a922-16bd888710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b127a-30b8-4a24-a865-651496f4627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_2 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3628f-ff15-46bd-82e2-c450859ce8dd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Gérer les valeurs manquantes (NaN)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "habitudes_indiv_clustering_2 = imputer.fit_transform(habitudes_indiv_clustering_1)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e056ea-5177-4c34-aa98-47b238550404",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etape 3 : Normalisation des colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ba789-3745-41a7-b4b4-5d4352167572",
   "metadata": {},
   "source": [
    "Pour la plupart des méthodes que nous allons utiliser, nous ne souhaitons pas nécessairement donner plus d'importance à une colonne qu'à une autre.\n",
    "Or pour plusieurs des fonctions que nous allons manipuler, le poids affecté à une colonne peut dépendre de sa moyenne ou de sa variance.\n",
    "\n",
    "Ici, les questions étant pour la plupart binaires, nous ne voulons pas qu'une question avec davantage de réponses positives ait une importance plus grande qu'une autre.\n",
    "Nous devons donc renormaliser les colonnes pour corriger ce problème.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efd0cf-c7a4-4947-8122-96585b51042c",
   "metadata": {},
   "source": [
    "A vous de jouer : renormalisez l'ensemble des colonnes pour amener leur moyenne à 0 et leur variance à 1. Vous stockerez le résultat dans le tableau ```habitudes_indiv_clustering_3```.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```StandardScaler``` du package ```sklearn.preprocessing```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e56e9-b966-40df-9c8f-4736f1a86968",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_3 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21905f6-526b-46c8-a9ec-96d77f230cab",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normaliser les colonnes\n",
    "scaler = StandardScaler()\n",
    "habitudes_indiv_clustering_3 = scaler.fit_transform(habitudes_indiv_clustering_2)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401c50f-a004-466c-a97a-f19044bed319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etape 4 : Gestion des outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbd468-56f6-4755-8c16-1ff319ebe9ba",
   "metadata": {},
   "source": [
    "Dans ce type de questionnaire il n'est pas rare de trouver des observations aberrantes, par exemple en raison d'individus répondant de façon absurde aux questions.\n",
    "De façon générale, si la base de données est suffisamment grande et que l'on ne s'intéresse pas nécessairement à chaque individu, une bonne pratique peut être de retirer les outliers de notre base.\n",
    "Cela permet en effet de limiter les risques d'avoir des clusters à un seul individu ne représentant rien d'intéressant ou d'avoir des visualisations déformées par une observation très loin par rapport aux autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8764c9-103e-4fd0-8e15-c4320d5c2402",
   "metadata": {},
   "source": [
    "A vous de jouer : retirez les outliers de la table ```habitudes_indiv_clustering_3```, disons 5% des observations, et stockez le résultat dans la table ```habitudes_indiv_clustering_4```.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```IsolationForest``` du package ```sklearn.ensemble```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa22d3-9d7c-44b1-92d9-bf70a7931107",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_4 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda9b15-1c1c-45cf-a319-072891eece3e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Détecter et retirer les outliers\n",
    "outlier_detector = IsolationForest(contamination=0.05, random_state=0)\n",
    "outlier_labels = outlier_detector.fit_predict(habitudes_indiv_clustering_3)\n",
    "habitudes_indiv_clustering_4 = habitudes_indiv_clustering_3[outlier_labels == 1]\n",
    "\n",
    "habitudes_indiv_clustering_4.shape\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6dd01-e3be-433c-80e7-37a4c71e5b44",
   "metadata": {},
   "source": [
    "Si vous le souhaitez, vous pourrez dans un second temps reproduire la suite sans retirer les outliers pour comparer les résultats obtenus.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16303c23-bae3-478c-bde2-d822093633d8",
   "metadata": {},
   "source": [
    "Vous avez à présent terminé le preprocessing de la table pour la partie Clustering.\n",
    "Libre à vous de rajouter des opérations supplémentaires si vous en voyez le besoin.\n",
    "Sinon nous pouvons rentrer dans le vif du sujet.\n",
    "\n",
    "Pour simplifier les notations, exécutez la cellule ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6b809-7028-4ebd-b361-8de0f7090322",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering = np.copy(habitudes_indiv_clustering_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f753dc2-3c24-48d3-b9c5-38c229463cdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Le clustering en lui-même"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928c114-9d3a-4029-a10f-390b7896e5ae",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons mettre en pratique les 2 méthodes de clustering les plus classiques :\n",
    "- Les K-Moyennes (ou K-Means)\n",
    "- Le Clustering Ascendant Hiérarchique (CAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf647d-d2b7-40fc-a3ad-67e5d0b6cde0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### K-Moyennes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7638f-4c80-4f3b-a07d-38737d03f079",
   "metadata": {},
   "source": [
    "Dans ce sujet, nous ne revenons pas sur la théorie derrière l'algorithme du K-Means.\n",
    "Donc si vous êtes intéressés pour savoir ce qui se passe derrière l'utilisation du package en boîte noire, la documentation sur cette thématique est largement disponible sur Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b50f93-d287-45f4-b84c-a9dc36543a19",
   "metadata": {},
   "source": [
    "##### Choisir le nombre de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d029f-1042-409a-8e47-84dd262d227e",
   "metadata": {},
   "source": [
    "Une particularité des K-moyennes est qu'il faut choisir en amont de l'application de l'algorithme le nombre de clusters (ou de centroïdes) ```k```, a priori sans savoir quel serait le nombre optimal.\n",
    "Il existe plusieurs méthodes pour faire ce choix :\n",
    "- S'il existe des contraintes métier ou des interprétations relatives au \"monde réel\" imposant une valeur de ```k```\n",
    "- En utilisant la méthode dite du __coude__, qui est la façon la plus simple d'avoir une idée de ```k``` à utiliser.\n",
    "    + Le principe est de lancer le K-means avec plusieurs valeurs de ```k```, représenter une mesure de la distance moyenne intra-clusters en fonction de ```k``` et trouver le premier point d'inflexion\n",
    "    + En revanche, le ```k``` renvoyé n'est pas toujours stable et parfois peu pertinent.\n",
    "- En utilisant la méthode dite de __silhouette__, méthode a priori plus fine mais un peu plus complexe que celle du coude\n",
    "    + Le score à maximiser par rapport à ```k``` est cette fois la moyenne d'une mesure de la similitude d’une observation à l’intérieur d’un groupe par rapport à d’autres groupes pour chaque point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe8f98-3c8d-4d89-b8fc-223a3a1aee58",
   "metadata": {},
   "source": [
    "A titre d'exemple, utilisez la méthode du coude pour trouver le nombre optimal de clusters pour les données de ```habitudes_indiv_clustering```. On cherchera un ```k``` compris entre 1 et 10.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```KElbowVisualizer``` du package ```yellowbrick.cluster```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f935d28-93bb-4c86-867a-d26d0e487160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e2e9c-58d5-40e4-901c-b96ede0e1d7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "elbow_method = KElbowVisualizer(KMeans(), k=(1,10))\n",
    "elbow_method.fit(habitudes_indiv_clustering)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45aa1f-ec6e-4350-a5d0-c3e44b41bde9",
   "metadata": {},
   "source": [
    "Quel est le ```k``` obtenu ? Cette valeur reste-t-elle la même si vous lancez la méthode plusieurs fois ?\n",
    "\n",
    "S'il n'y a pas de point d'inflexion (ou coude) bien défini sur le graphique produit, la valeur peut souvent varier. Pour la suite du sujet, nous conserverons une valeur fixe, que vous pourrez modifier par la suite si vous le souhaitez. Exécutez la ligne ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b87b0-c8c7-4a0d-8255-df36e0050f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_kmeans = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ed92f-7e74-4dfb-b8b8-5111eb1e3ac4",
   "metadata": {},
   "source": [
    "##### Le clustering en lui-même"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d562e-dd02-41f1-9b8c-dd0aeb48f14b",
   "metadata": {},
   "source": [
    "Une fois les données préprocessées et le ```k``` déterminé, clusteriser les données n'est plus très difficile.\n",
    "\n",
    "A l'aide de la documentation de la fonction ```KMeans()``` du package ```sklearn.cluster```, créez le vecteur ```clusters_kmeans``` des clusters obtenus par la méthode des K-moyennes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30946355-8b2e-44d3-871e-5e1fe90b7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e4962-f8d8-4c72-add6-c9d37967471e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=k_kmeans, random_state=0)\n",
    "clusters_kmeans = kmeans.fit_predict(habitudes_indiv_clustering)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b36d0e-ba52-48bd-ae65-247b7b6bb2c8",
   "metadata": {},
   "source": [
    "Félicitations, vous avez désormais vos clusters !\n",
    "Pouvez-vous dire quelle est la taille de chacun ? Ces valeurs sont-elles proches les unes des autres ? Pouvez-vous déjà interpréter vos résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f529d-171e-464b-8a87-8f8d3b82603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3d960-2c1f-4e4e-b741-e9ea77fc0361",
   "metadata": {},
   "source": [
    "On a certes obtenu nos clusters, mais tout cela n'est pas encore très visuel...\n",
    "\n",
    "Mais pas de panique, plus que quelques cellules à attendre pour passer à la visualisation par ACP !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd856808-5dca-42e1-aa95-920fabe9990f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Clustering Ascendant Hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfca4d-31c0-474d-b489-dbe1de5b9405",
   "metadata": {},
   "source": [
    "Avant de passer à la visualisation, nous allons nous attarder sur une autre méthode de clustering, à peu près équivalente aux K-moyennes en termes de performances, mais dont les résultats sont beaucoup plus visuels : le [CAH](https://www.xlstat.com/fr/solutions/fonctionnalites/classification-ascendante-hierarchique-cah). Comment est-ce que ça marche ?\n",
    "\n",
    "- On commence par calculer la dissimilarité entre nos N individus, ie leur distance deux à deux dans l'espace de nos variables\n",
    "- Puis on regroupe les deux individus dont le regroupement minimise un critère d'agrégation donné, créant ainsi une classe comprenant ces deux individus.\n",
    "- On calcule ensuite la dissimilarité entre cette classe et les N-2 autres individus en utilisant le critère d'agrégation.\n",
    "- Puis on regroupe les deux individus ou classes d'individus dont le regroupement minimise le critère d'agrégation.\n",
    "- On continue ainsi jusqu'à ce que tous les individus soient regroupés.\n",
    "\n",
    "Ces regroupements successifs produisent un arbre binaire de classification (_dendrogramme_), dont la racine correspond à la classe regroupant l'ensemble des individus.\n",
    "Ce dendrogramme représente une hiérarchie de partitions.\n",
    "On peut alors choisir une partition en tronquant l'arbre à un niveau donné, le niveau dépendant soit des contraintes de l'utilisateur, soit de critères plus objectifs.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ced51-dab0-4f0d-88c9-1099d91724e4",
   "metadata": {},
   "source": [
    "Dans ce sujet, nous allons nous limiter à la méthode d'agrégation la plus standard, dite de __Ward__.\n",
    "En utilisant la fonction ```linkage``` du package ```scipy.cluster.hierarchy```, créez les regroupements successifs mentionnés plus haut.\n",
    "Le résultat tient en deux lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae640c8b-3892-4784-bfea-d5e658c4cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regroupements = '' # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073e0bc-80cd-4f7b-ade1-460b0fe33c68",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# Utiliser la méthode linkage pour effectuer le clustering hiérarchique\n",
    "regroupements = linkage(habitudes_indiv_clustering, method='ward')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cb913-023c-45b2-9dff-0e9ee93d268a",
   "metadata": {},
   "source": [
    "Maintenant les regroupements effectués, nous pouvons dessiner le dendrogramme les représentant.\n",
    "Pour des contraintes de lisibilité, nous vous demanderons de limiter l'affichage de l'arbre à une profondeur de 6.\n",
    "\n",
    "En utilisant les packages ```matplotlib.pyplot``` et ```sklearn.cluster.hierarchy```, représentez le dendrogramme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03386895-d47c-4040-a399-aab1457d1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "profondeur_a_afficher = 6\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# TODO\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75028e-69e9-4c0f-b4f1-be44cc5a0bd0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster.hierarchy import dendrogram\n",
    "\n",
    "profondeur_a_afficher = 6\n",
    "\n",
    "# Afficher le dendrogramme\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(regroupements,\n",
    "           truncate_mode='level',\n",
    "           p=profondeur_a_afficher)\n",
    "\n",
    "plt.title(\"Dendrogramme sur la table des habitudes alimentaires\")\n",
    "plt.xlabel(\"Classes d'individus\")\n",
    "plt.ylabel(\"Distance entre les classes\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beefdd5-f525-4036-abd1-ddbc8070f287",
   "metadata": {},
   "source": [
    "Si tout s'est bien passé jusqu'ici, vous devriez avoir un magnifique dendrogramme sous les yeux !\n",
    "\n",
    "Cependant une question demeure : jusque-là la problématique du nombre de clusters à utiliser ne s'est toujours pas posée, comment allons-nous choisir maintenant ?\n",
    "Encore une fois, des contraintes du monde réel peuvent venir diriger le choix.\n",
    "Si ce n'est pas le cas, on peut faire par rapport à l'allure du dendrogramme, en choisissant une coupe horizontale de l'arbre cohérente.\n",
    "Cette coupe détermine alors les clusters finaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f8697-8f60-497b-a9ee-299cc822aa9c",
   "metadata": {},
   "source": [
    "En utilisant la fonction ```fcluster``` du package ```sklearn.cluster.hierarchy```, réalisez cette coupe du dendrogramme au niveau ```k_cah = 3``` pour créer le vecteur ```clusters_cah``` des clusters obtenus par CAH. Une fois les clusters générés, que pouvez-vous en dire ? Est-ce cohérent avec votre dendrogramme ?\n",
    "\n",
    "Une fois le reste du sujet effectué, vous pourrez également reprendre cette partie avec ```k_cah = 4```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c3cbd-acb4-4b5c-bb2e-aa93acb3215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cah = 3  # Nombre de clusters souhaité\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387b6a9-709d-49cf-955a-0da7dd33c7d0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.cluster.hierarchy import fcluster\n",
    "\n",
    "k_cah = 3  # Nombre de clusters souhaité\n",
    "clusters_cah = fcluster(regroupements, k_cah, criterion='maxclust')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6750427-157a-4e32-a4d2-29c7c60fd6a7",
   "metadata": {},
   "source": [
    "Maintenant les clusters obtenus par deux méthodes différentes, il est temps de passer à la visualisation !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6725dcb-dc38-4688-ace7-309e7602e770",
   "metadata": {},
   "source": [
    "### 3. Visualisations et interprétations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e83ad-c992-4b61-9cea-f0a2bb7a9f47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Réaliser l'ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b2f16-ba6d-4e1e-a74a-16e7fe49ff14",
   "metadata": {},
   "source": [
    "La méthode la plus simple pour visualiser nos clusters serait de représenter chaque individu dans l'espace à N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.\n",
    "On pourrait alors bien différencier les variables les plus discrimantes et les différents groupes.\n",
    "Un seul problème ici : dès que N > 3, nous avons du mal à représenter le résultat de façon intelligible...\n",
    "\n",
    "C'est là qu'intervient __l'Analyse en Composantes Principales__ ([ACP](https://www.xlstat.com/fr/solutions/fonctionnalites/analyse-en-composantes-principales-acp)), qui permet de projeter notre espace à haute dimension dans un espace de dimension plus petite.\n",
    "La contrainte majeure de la projection est de pouvoir conserver le maximum d'information (mesurée par la variance totale de l'ensemble de données) dans notre nombre réduit de dimensions, appelées composantes principales.\n",
    "En se limitant à 2 ou 3 dimensions, on peut ainsi se représenter visuellement les relations entre les observations avec une perte de fiabilité minimale.\n",
    "\n",
    "Dans notre situation, on peut espérer que les clusters déterminés dans notre espace à N dimensions se différencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d'interpréter les clusters obtenus. Nous allons donc tester cette hypothèse !\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836d22f-cb8d-41af-9222-ce5c75c96b68",
   "metadata": {},
   "source": [
    "Nous allons commencer par le calcul des 3 composantes principales. Créez :\n",
    "- Un dataframe ```composantes_principales``` avec les mêmes colonnes que ```habitudes_indiv_clustering```, de longueur 3, où la ligne i correspond à la i-ème composante principale obtenue par l'ACP, et où chaque case correspond à la contribution relative de la variable j à à la composante i.\n",
    "- Un dataframe ```projection_individus``` correspondant à la projection des individus de ```habitudes_indiv_clustering``` dans l'espace des composantes principales. Ce dataframe aura donc 3 colonnes, que l'on pourra nommer [PC1, PC2, PC3].\n",
    "\n",
    "Vous pourrez utiliser la fonction ```PCA``` du package ```sklearn.decomposition``` ainsi que les différentes méthodes associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83040b01-8daf-4ec4-bf90-a0691e9edfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_composantes_principales = 3\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d933a64-ad22-4afd-acfd-2c528b8c266b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "nb_composantes_principales = 3\n",
    "\n",
    "# Effectuer l'ACP\n",
    "acp = PCA(n_components=nb_composantes_principales)\n",
    "projection_individus_array = acp.fit_transform(habitudes_indiv_clustering)\n",
    "projection_individus = pd.DataFrame(data=projection_individus_array, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Obtenir les poids des caractéristiques pour chaque composante principale\n",
    "composantes_principales = pd.DataFrame(acp.components_, columns=habitudes_indiv_clustering.columns)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74527adb-734f-4f47-968a-39bc3b85bc5e",
   "metadata": {},
   "source": [
    "Maintenant l'ACP terminée, nous allons tâcher d'interpréter les composantes principales obtenues.\n",
    "En effet, la combinaison linéaire des colonnes donnant naissance à nos nouveaux axes a souvent un \"sens\" dans le monde réel :\n",
    "- Soit parce qu'une petite poignée de variables représente la majorité de la composante\n",
    "- Soit parce que la plupart des colonnes intervenant dans la composante sommée se combinent bien pour former une interprétation naturelle.\n",
    "\n",
    "Ici, cela pourrait par exemple être :\n",
    "- La 1ère composante quasiment égale à une somme des variables \"Mange bio\", \"Mange de saison\" et \"Mange local\", montrant ainsi que l'axe le plus discriminant serait le fait pour un individu de se nourrir de façon plus ou moins écologique.\n",
    "- La 2è composante définie comme la somme pour tous les sports de la variable \"Pratique x sport régulièrement\", donnant ainsi un second axe discriminant les individus plus ou moins sportifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29123de4-58f0-4fd5-a449-b398ae7cb021",
   "metadata": {},
   "source": [
    "Voyons ce que cela donne sur nos données. En utilisant la table ```composantes_principales``` et la fonction ```barh``` du package ```matplotlib.pyplot```, représentez les 20 variables les plus importantes (en termes de poids absolu) pour la 1ère composante de l'ACP, ainsi que leur contribution relative à la composante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67aa881-5b91-4ca5-b690-8580166795ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_top_features = 20\n",
    "\n",
    "# TODO\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9266-b8cc-4d3b-ba10-bd08bbeb9b96",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "nb_top_features = 20\n",
    "\n",
    "# Sélectionner les 20 caractéristiques les plus importantes pour PC1\n",
    "pc1_top_features_abs = composantes_principales.iloc[0].abs().nlargest(nb_top_features, keep='all')\n",
    "pc1_top_features = composantes_principales.iloc[0].loc[pc1_top_features_abs.index]\n",
    "\n",
    "# Afficher les poids des caractéristiques pour PC1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(pc1_top_features.index, pc1_top_features.values)\n",
    "plt.title(f'{nb_top_features} variables les plus représentées pour PC1')\n",
    "plt.xlabel('Poids')\n",
    "plt.ylabel('Variables')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dacbeb-1774-4044-8d35-20aa02f14aff",
   "metadata": {},
   "source": [
    "Faites ensuite la même chose pour PC2 et pour PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380680f-cf47-4111-8ff5-9f51dae9a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ef8ae-5f07-47e0-be2c-bc37b7542c4c",
   "metadata": {},
   "source": [
    "A présent, comment pouvez-vous interpréter vos résultats ?\n",
    "Êtes-vous capables de donner un sens aux combinaisons linéaires obtenues ?\n",
    "Peut-on renommer nos variables \"PC1\", \"PC2, \"PC3\" ?\n",
    "\n",
    "Si vous ne vous souvenez plus de la signification des variables, vous pouvez retrouver le dictionnaire des variables ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df0fcc-3195-4e19-831f-312ca20afcee",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "Il n'est pas garanti que vous retrouviez exactement les mêmes résultats, mais voici une proposition d'interprétation suite à l'exécution des codes du corrigé :\n",
    "- PC1 : Une mesure agrégée représentant à quel point l'individu a tendance à produire lui-même ce qu'il mange\n",
    "    - Nombreuses variables commençant par \"autoproduction\" et \"autoconso\" avec des poids positifs\n",
    "- PC2 : Une mesure agrégée représentant à quel point l'individu a tendance à manger bio\n",
    "    - Nombreuses variables contenant le mot \"bio\" avec des poids positifs\n",
    "- PC3 : Plus difficile à interpréter, une mesure agrégée de préférences alimentaires liées aux produits frais\n",
    "    - A quel point l'individu est-il prompt à manger frais (fruits & légumes, produits laitiers) ?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4ffb9-6aaa-4009-9b6a-db1f1fd6b95c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Et le clustering dans tout ça ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35217e-3d79-4085-a7b2-3c250cf3ba5a",
   "metadata": {},
   "source": [
    "Nous avons notre projection sur 2 ou 3 dimensions, nous avons interprété ces nouveaux axes, il s'agit donc maintenant de faire ce pour quoi l'ACP a initialement été réalisée : l'observation des clusters.\n",
    "\n",
    "Pour commencer, créez la table ```projection_individus_et_clusters``` concaténant les tables ```projection_individus```, ```clusters_kmeans``` et ```clusters_cah```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163e636-7773-442c-b2b1-2f9548f30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa0f7f-d45a-4044-9c4b-722222068fc5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "projection_individus_et_clusters = projection_individus.copy()\n",
    "projection_individus_et_clusters['cluster_kmeans'] = clusters_kmeans\n",
    "projection_individus_et_clusters['cluster_cah'] = clusters_cah\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d878023-e631-4422-a991-b04fed6c4c64",
   "metadata": {},
   "source": [
    "A présent, il ne vous reste plus qu'à utiliser la méthode ```.scatter()``` du package ```matplotlib.pyplot``` pour représenter vos individus dans l'espace __2D__ généré par les composantes PC1 et PC2. Concentrons-nous d'abord sur les clusters par K-moyennes : vous colorierez donc vos points en fonction de la valeur de la colonne 'cluster_kmeans'. A vous de jouer !\n",
    "\n",
    "Bonus : N'hésitez pas à renommer vos axes pour leur donner des noms plus explicites en fonction des interprétations que vous avez faites précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5879d-1884-43a2-8835-d21b2c1da95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32e25a-df88-408e-a57f-b35d1cc2cbe0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Afficher le graphique des clusters en 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter_plot = plt.scatter(\n",
    "    projection_individus_et_clusters['PC1'],\n",
    "    projection_individus_et_clusters['PC2'],\n",
    "    c=projection_individus_et_clusters['cluster_kmeans'],\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "plt.legend(handles=scatter_plot.legend_elements()[0], labels=range(k_kmeans))\n",
    "plt.title('Individus groupés par tendances alimentaires')\n",
    "plt.xlabel('PC1 - Production & consommation de sa propre nourriture')\n",
    "plt.ylabel('PC2 - Consommation d\\'aliments bio')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e187a-4a9f-4996-803e-7d3923b421cf",
   "metadata": {},
   "source": [
    "Plutôt cool, non ?\n",
    "La grande question maintenant : vos clusters se différencient-ils bien sur votre visualisation ? Si les choses sont bien faites, il devrait y avoir peu de superposition des différents groupes.\n",
    "\n",
    "Pouvez-vous maintenant caractériser vos clusters en fonction de leur position sur votre graphe ? Vous avez ainsi vos _individus-types_ permettant de schématiser votre population.\n",
    "\n",
    "A présent, faites pareil sur les clusters obtenus par CAH, obtenez-vous exactement les mêmes clusters ? L'interprétation que vous avez faite change-t-elle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011e03a-d52e-47e3-94b3-ea9d0ed8405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c9664-7330-460c-84d9-5c7fb8c8f49e",
   "metadata": {},
   "source": [
    "Pour terminer, quid d'utiliser notre 3è composante principale dans notre représentation graphique ?\n",
    "Utilisez la fonction ```.scatter()``` pour réaliser cette fois un graphe en __3 dimensions__ dans lequel représenter vos individus.\n",
    "Comment évolue l'apparence de vos clusters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9601eaf-5d58-40f7-9d34-7a3b1752c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348476ba-6ed7-4026-8e85-90f31f194f04",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Afficher le graphique des clusters en 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "xs = projection_individus_et_clusters['PC1']\n",
    "ys = projection_individus_et_clusters['PC2']\n",
    "zs = projection_individus_et_clusters['PC3']\n",
    "ax.scatter(xs, ys, zs,\n",
    "           c=projection_individus_et_clusters['cluster_kmeans'],\n",
    "           cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('PC1 - Production & consommation de sa propre nourriture')\n",
    "ax.set_ylabel('PC2 - Consommation d\\'aliments bio')\n",
    "ax.set_zlabel('PC3 - Préférences produits frais')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0fab5-e545-4782-9153-d2b04bf8b14d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b591a2e-6286-48bf-8904-e0963eb69f8f",
   "metadata": {},
   "source": [
    "Vous avez à présent terminé la partie clustering du sujet. Si vous souhaitez aller plus loin, vous pouvez :\n",
    "\n",
    "- Reproduire toutes les exécutions en retirant seulement l'une des étapes du preprocessing, comme par exemple le traitement des outliers. Comment évoluent alors les clusters et visualisations ?\n",
    "    + Retirer les outliers peut souvent conduire à la création de clusters constitués d'un seul individu, très éloigné des autres sur l'ACP. Il faut donc traiter ce type d'observations à part ou bien augmenter le nombre de clusters pour compenser.\n",
    "\n",
    "<br>\n",
    " \n",
    "- Reproduire toutes les exécutions en changeant le nombre de clusters ```k``` : comment évoluent les clusters ? Que cela donne-t-il sur les ACP ?\n",
    "    + Le cas ```k = 4``` est particulièrement intéressant : les clusters semblent se superposer sur les visualisations en 2D, mais on se rend compte lors de la visualisation 3D que les clusters prétendumment superposés se différencient en fait très bien si l'on rajoute la 3è composante principale. Cela permet alors de caractériser encore plus finement nos individus types.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Reproduire toutes les exécutions sur une autre table que celles des habitudes alimentaires.\n",
    "    + Nous vous recommandons par exemple d'essayer avec :\n",
    "        - ```actphys_sedent``` : questionnaire sur l'activité physique des répondants\n",
    "        - ```fpq``` : questionnaire sur le fréquential alimentaire des individus\n",
    "    + Comment les clusters s'interprètent-ils alors ? Quels sont nos individus-types ?\n",
    "    + Si vous souhaitez aller encore plus loin, vous pouvez faire une jointure sur les différentes tables et opérer le clustering sur la table jointe afin de voir quelles sont les caractéristiques les plus discriminantes.\n",
    "    + Pour les autres tables, attention à ne bien garder que des variables numériques, et par exemple faire du _one-hot encoding_ sur les variables catégorielles codées sur des nombres entre 1 et 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6b3f-ef3b-4c6c-82be-14daae9869aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7c031-d534-4624-9723-e862e432a70a",
   "metadata": {},
   "source": [
    "# Fin :)\n",
    "\n",
    "Si vous voulez toucher à de la régression et de l'apprentissage supervisé, n'hésitez pas à revisiter le sujet en Python !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e1352-e678-40b3-b17f-1c75b4aa26f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
