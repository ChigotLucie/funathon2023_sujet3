{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beecbc70",
   "metadata": {},
   "source": [
    "# Partie 3 : Premiers pas vers les méthodes de ML supervisé en python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c721ac0",
   "metadata": {},
   "source": [
    "L'idée de cette partie est de tester différentes méthodes d'apprentissage statistique supervisées usuelles. Pour cela nous allons utiliser les données issues de la table de description des individus interviewés lors de l'enquête INCA 3 sur la consommation et les habitudes alimentaires des français.\n",
    "\n",
    "L'objectif consistera à prédire au mieux l'IMC d'un individu grâce aux diverses informations que nous détenons sur la personne. Contrairement à la partie 2 sur le clustering, il s'agit ici de d'apprentissage supervisé car nous avons en notre possessions des données labélisées. Parmi les méthodes d'apprentissages supervisé on distingue généralement deux grandes familles que sont la classification et la régression. Ici nous sommes confronté à un problème de régression puisque nous souhaitons prédire l'indice de masse corporelle exacte. Pour cela nous allons tester plusieurs méthodes différentes afin d'analyser lesquelles sont les plus efficaces sur les données que nous possédons.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c510f9",
   "metadata": {},
   "source": [
    "## 1. Prise en main des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65b5d4b1",
   "metadata": {},
   "source": [
    "Les données de l'enquête INCA3 sont disponibles sur *Data.gouv* à l'adresse suivante : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/. Cette table contient les données des questionnaires face-à-face relatifs aux volets « Socio-économique » et « Mesures anthropométriques » et des données des questionnaires auto-administrés relatifs aux volets « Etat de santé » et « Tabagisme ». \n",
    "\n",
    "Elle regroupe les informations suivantes : caractéristiques socio-démographiques de l’individu (ou de son représentant dans le cas des enfants), caractéristiques\n",
    "socio-démographiques de la personne de référence du foyer, niveau de vie du foyer, insécurité alimentaire, caractéristiques anthropométriques (poids, taille, indice\n",
    "de masse corporelle, statut pondéral) ; statut vis-à-vis d’allergies ou d’intolérances alimentaires, types de régimes alimentaires, types d’allergies ou d’intolérances\n",
    "alimentaires, régimes et histoire pondérale, statut vis-à-vis de la grossesse, de l’allaitement et de la ménopause (uniquement pour les femmes de 15 ans et plus),\n",
    "statut tabagique ; indicateurs de sous ou sur-déclaration en termes de consommations alimentaires.\n",
    "\n",
    "Nous avons préalablement selectionné un grand nombre de variables issues de cette base que nous avons ensuite enregistré dans un bucket s3. Vous pouvez les télécharger grâce à ma commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f72cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow import fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430475",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
    "\n",
    "bucket = \"projet-funathon\"\n",
    "path_data =  \"2023/sujet3/diffusion/description_individu_inca.parquet\"\n",
    "\n",
    "df = pq.ParquetDataset(f'{bucket}/{path_data}', filesystem=s3).read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63af787d",
   "metadata": {},
   "source": [
    "<i  class=\"fa fa-pencil\"></i> On peut tout d'abord remarquer que le jeu de données ne semble, a priori, pas idéal pour réaliser des méthodes de machine learning très complexes avec beaucoup de paramètres à estimer. Il arrive très souvent que des méthodes plus classiques soient aussi, voire plus, efficaces que les méthodes d'apprentissage statistique. Cependant ce jeu de données peut tout à fait être utilisé à des fins pédagogiques pour comprendre les principes généraux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20461c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6ae1b18",
   "metadata": {},
   "source": [
    "Tout d'abord, commençons par définir quelques constantes qui nous seront utiles pour la suite, à savoir : \n",
    "- La variable d'intérêt que nous cherchons à prédire `TARGET_VARIABLE`\n",
    "- La variable correspondant au numéro d'individu `NOIND`\n",
    "- Un nombre arbitraire pour afin de simplifier la réplicabilité de nos expérimentations `SEED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afeedb4-ef62-4ca3-bde7-8c81e20c0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VARIABLE=\"imc\"\n",
    "INDEX=\"NOIND\"\n",
    "SEED=2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e98384fd",
   "metadata": {},
   "source": [
    "**Question 1:** Comme souvent en science de la données, la partie la plus fastidieuse consiste à analyser les données à notre disposition. En vous aidant du dictionnaire accessible [ici](https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf) déterminer l'ensemble des variables numériques. Les autres variables seront considérées comme des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\n",
    "# VOTRE CODE\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24b78538",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997bff29",
   "metadata": {},
   "source": [
    "Une pratique courante dans les projets de machine learning c'est de commencer par spécifier une fraction de notre jeu données comme un **échantillon de test**. Cet échantillon va être utilisé à la toute fin du projet de sorte à évaluer la performance de nos modèles sur des données qu'il n'aura jamais vu auparavant. L'échantillon restant, celui **d'entrainement**, est lui utilisé pour entrainer les algorithmes et comparer leurs performances. L'idée derrière cette division est de réduire le risque de sur-apprentissage de notre modèle et d'estimer une erreur de généralisation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "935d6713",
   "metadata": {},
   "source": [
    "**Question 2:** Créer les variables `y` et `X` correspondant respectivement à la variable d'intérêt et aux différentes features de notre jeu de données. Diviser ensuite ce jeu de données en un échantillon de train et de test en utilisant la fonction `train_test_split` de [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Ne pas oublier de spécifier le `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a3dba9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_VARIABLE]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_VARIABLE]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f174eaa4",
   "metadata": {},
   "source": [
    "## 2. Un modèle de régression linéaire simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d324b88",
   "metadata": {},
   "source": [
    "**Question 3:** Avant d'étudier différentes méthodes d'apprentissage statistique commençons par réaliser une régression linéaire classique. Pour cela, sélectionnez un petit nombre de variables $(< 10)$ qui vous semble pertinent pour prédire l'indice de masse corporelle d'une personne. Prenez à la fois des variables numériques et catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd56601",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_REGRESSION = [\n",
    "# VOTRE CODE\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "# VOTRE CODE\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "    \"poids_perception\" ,\n",
    "    \"enceinte\",\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5beca656",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "   # \"tage_PS_mois\",\n",
    "   # \"diplome_interv\",\n",
    "   # \"soins\",\n",
    "   # \"situ_fin_3cl\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "   # \"IA_statut\",\n",
    "   # \"statnut\",\n",
    "    \"poids_perception\" ,\n",
    "   # \"menopause\",\n",
    "    \"enceinte\",\n",
    "   # \"enceinte_12dermois\",\n",
    "   # 'etude_4cl_interv',\n",
    "   # 'situ_prof_5cl_interv',\n",
    "   # 'atrav_interv',\n",
    "   # 'trav_nuit_interv',\n",
    "   # 'trav_nuit_2cl_interv',\n",
    "   # 'PCS_8cl_interv',\n",
    "   # 'PCS_4cl_interv',\n",
    "   # 'tps_travail_interv',\n",
    "   # 'vacances_interv',\n",
    "   # 'RUC_4cl',\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "   # \"bmr_kcal\",\n",
    "   # 'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5068cd-d2f1-4edd-a5e3-2e131c7c39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train[FEATURES_REGRESSION]\n",
    "X_test_regression = X_test[FEATURES_REGRESSION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87529e-74d9-49e4-a1bf-ed597d3cf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a2ebf40",
   "metadata": {},
   "source": [
    "Ces informations nous indiquent qu'il y a plusieurs variables qui contiennent des valeurs manquantes. Afin de ne pas supprimer les lignes qui contiennent des valeurs manquantes nous allons tenter de les imputer. Plusieurs méthodes d'imputations peuvent être réalisées :\n",
    "\n",
    "- **Pour les variables numériques:** Il est courant de remplacer les variables manquantes par la moyenne ou la médiane de l'échantillon.\n",
    "- **Pour les variables catégorielles:** On peut remplacer les variables manquantes par le moden c'est à dire la valeur la plus fréquente dans l'échantillon ou en créant une nouvelle categorie reflétant une valeur manquante.\n",
    "\n",
    "D'autres méthodes qui requiert plus de modélisation sont également possible comme réaliser une régression afin de prédire les valeurs manquantes grâce aux autres features ou  utiliser un algorithme de K plus proche voisin. Toutes ces méthodes ont à la fois leurs avantages et leurs inconvénients, il est important de déterminer celle qui est la plus approprié pour le problème que vous souhaitez résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cf28e27",
   "metadata": {},
   "source": [
    "**Question 4:** Pour faire simple, nous allons remplacer les valeurs manquantes des variables numériques par la médiane et pour celles des variables catégorielles nous allons créer une nouvelle catégorie qui sera égale à $-1$. Ce dernier choix vous semble t-il approprié ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6b0f2dc",
   "metadata": {},
   "source": [
    "**Question 5:** En vous aidant de la (documentation)[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute] de scikit learn , créez ces deux *Imputer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = # VOTRE CODE\n",
    "median_imputer = # VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3177739",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f560f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b74119c3",
   "metadata": {},
   "source": [
    "**Question 6:** Analysez les modalités de la variables `enceinte_nbmois`, une imputation par la moyenne vous semble-t-elle justifiée ? Si non, proposez une autre imputation. Existe t-il d'autres variables dans ce cas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = # VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03399840",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pd.unique(X_train_regression[\"enceinte_nbmois\"])\n",
    "```\n",
    "\n",
    "```python\n",
    "# Les valeurs manquantes correspondent plutôt à la modalité \"pas enceinte\", il est donc plus judicieux de remplacer les valeurs manquantes par 0.\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ded42c4",
   "metadata": {},
   "source": [
    "Une étape très importante lorsqu'on utilise des méthodes de machine learning est la standardisation des données afin de mettre toutes les variables à la même échelle. Lorsque les variables ont des échelles différentes, certaines peuvent dominer les autres dans le processus d'apprentissage, ce qui peut fausser les résultats. Plusieurs méthodes de standardisation peuvent être utilisées, les deux plus courantes sont: \n",
    "- la normalisation standard : $z = \\frac{x - \\bar{x}}{\\sigma}$\n",
    "- la normalisation 0-1 : $z = \\frac{x - min}{max - min}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aa43ba5",
   "metadata": {},
   "source": [
    "Nous pouvons donc créer une pipeline dans laquelle nos *features* passeront afin de subir diverses transformations. En l'occurence, nous souhaitons que nos les valeurs manquantes *features* soient imputées et que ces dernières soit standardisées. Pour cela nous pouvons utiliser la fonction `make_pipeline`. Pour le *scaler* nous allons utiliser la normalisation standard qui peut être réalisée grâce à la méthode `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc77a99",
   "metadata": {},
   "source": [
    "Une fois nos *pipelines* définies ils faut déterminer quelles *features* passent par quelles *pipelines*. Dans notre cas, on souhaite que les variables catégorielles traversent la pipeline qui impute les valeurs manquantes par $-1$ et les variables numériques par la pipeline qui impute soit par la médiane, soit par 0. Pour cela on doit utiliser la fonction `ColumnTransformer`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc634d2",
   "metadata": {},
   "source": [
    "**Question 7:** En vous référant à la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) de la fonction, créez votre pipeline de preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    # VOTRE CODE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ed35c11",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89cd6074",
   "metadata": {},
   "source": [
    "Maintenant que nos étapes de *preprocessing* sont définies, on peut les réaliser et observer les changements qui ont été opéré sur notre jeu de données afin de vérifier que les modifications ont bien été faites comme attendues. Pour cela, commencons par observer notre échantillon d'entrainement initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3c039f",
   "metadata": {},
   "source": [
    "Jusqu'à présent nous avons seulement définies les étapes de notre *preprocessing* mais celles ci n'ont pas été réalisées, pour cela nous devons `fit` notre preprocessing à notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_regression.fit(X_train_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_regression.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71788e0d",
   "metadata": {},
   "source": [
    "`Scikit-learn` juxtapose automatiquement le nom de la transformation effectuée à la variable. Pour simplifier la comparaison nous allons supprimer ce qui a été rajouté en prefixe de sorte à retrouver les même nom de variable qu'initialement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "original_feature_names = [re.sub(r'^.*__', '', item) for item in preprocessor_regression.get_feature_names_out()]\n",
    "original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8232e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = pd.DataFrame(preprocessor_regression.fit_transform(X_train_regression), columns=original_feature_names)\n",
    "data_preprocessed.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2858a55b",
   "metadata": {},
   "source": [
    "Une fois qu'on a vérifié que le preprocessing nous convient on peut analyser la corrélation des différentes variables explicatives pour se prévenir du problème de la collinéarité. Pour cela, rien de mieux qu'une visualisation graphique pour obtenir une première idée !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0701761e",
   "metadata": {},
   "source": [
    "**Question 8:** Calculer la matrice de correlation des variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = # VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "553eb31a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "corr = data_preprocessed.corr()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_preprocessed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ff894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee93e9e",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant passer à la modélisation ! Sachant qu'on a déjà une *pipeline* qui contient les instructions pour le *preprocessing* il est très simple de rajouter une étape supplémentaire à cette pipeline afin de réaliser la modélisation. Pour estimer une régression linéaire nous allons utiliser une nouvelle fois une méthode de scikit-learn: `LinearRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor_regression), # 1ère étape réaliser le preprocessing\n",
    "    ('regression', LinearRegression()) # 2ème étape estime notre régression linéaire\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f85295d1",
   "metadata": {},
   "source": [
    "Comme précédemment, notre pipeline n'a pas été exécutée, nous l'avons seulement définie. Il est donc nécessaire de l'exécuter sur nos données grâce à la méthode `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pipe_lr.fit(X_train_regression, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08e140c2",
   "metadata": {},
   "source": [
    "**Question 9:** Prédisez les indices de masse corporelles des individus de votre échantillon de test à l'aide de votre modèle. Evaluez le en calculant l'écart quadratique moyen (RMSE) et le R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = # VOTRE CODE\n",
    "rmse = # VOTRE CODE\n",
    "r2 = # VOTRE CODE\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26894458",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lr.predict(X_test_regression)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lr.predict(X_test_regression)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ac4506",
   "metadata": {},
   "source": [
    "Il est difficile d'interpréter la valeur absolue du RMSE car il dépend de l'échelle et de la volatilité des données que nous cherchons à prédire. Regardons quelques statistiques de nl'IMC de nos individus de l'échantillons de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"La variance de l'IMC de jeu de test est : {round(y_test.var(), 4)}\")\n",
    "print(f\"La moyenne de l'IMC de jeu de test est : {round(y_test.mean(), 4)}\")\n",
    "print(f\"L'écart interquartile de l'IMC de jeu de test est : {round(y_test.quantile(0.75) - y_test.quantile(0.25), 4)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95c10717",
   "metadata": {},
   "source": [
    "On peut donc normaliser notre RMSE par l'une de ces statistiques pour avoir une idée plus précise des erreurs. La variance et la moyenne sont généralement les plus utilisées pour normaliser le RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4628e2d1",
   "metadata": {},
   "source": [
    "Une autre méthode qu'on ne saurait que vous recommander est une nouvelle fois la représentation graphique ! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a90ed79",
   "metadata": {},
   "source": [
    "**Question 10:** Représentez graphiquement les valeurs prédites par rapport aux vraies valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91c2d74f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creer le scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Ajout des labels\n",
    "plt.xlabel('Vrai IMC')\n",
    "plt.ylabel('IMC prédit')\n",
    "\n",
    "# Ajout de la ligne à 45° comme référence\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Affichagedu graphique\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5adfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creer le scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Ajout des labels\n",
    "plt.xlabel('Vrai IMC')\n",
    "plt.ylabel('IMC prédit')\n",
    "\n",
    "# Ajout de la ligne à 45° comme référence\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Affichagedu graphique\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30b2699",
   "metadata": {},
   "source": [
    "**Question 11:** Commentez le graphique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b92a7fdc",
   "metadata": {},
   "source": [
    "## 3. Méthodes de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97127511",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "013be7bb",
   "metadata": {},
   "source": [
    "Grâce à scikit learn, on va voir qu'il est très facile d'utiliser des méthodes de machine learning différentes maintenant qu'on a utilisé les fonctions de base lors de la régression linéaire. \n",
    "Nous allons maintenant essayer d'utiliser l'intégralité des variables qui nous sont disponibles dans la base de données initiale. Cela implique de se replonger un petit peu dans l'analyse des données. Nous avons vu précédemment que toutes les variables numériques ne pouvaient pas être imputées par la médiane et que dans certains cas une imputation par 0 est préférable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5df9841",
   "metadata": {},
   "source": [
    "**Question 12:** Répertoriez l'ensemble des variables numériques à imputer par 0 dans une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aeaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\n",
    "    # VOTRE CODE\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea2c97f8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL_0_IMPUT = [\n",
    "    \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\n",
    "    \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e6103c",
   "metadata": {},
   "source": [
    "**Question 13:** En vous aidant de ce qui a été fait précédemment, construisez un objet `preprocessor` qui imputera correctement toutes les variables de notre jeu de données d'entrainement, à savoir `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "317ed0bd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8676c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca6f1aed",
   "metadata": {},
   "source": [
    "**Question 14:** De la même manière que ce qui a été fait en 2., construisez une pipeline qui preprocesse vos données avant d'estimer un modèle Random Forest. N'oubliez pas de spécifier un `random_state` pour pouvoir répliquer vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe_rfr = #VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07369b57",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac48219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf9c556f",
   "metadata": {},
   "source": [
    "Lorsque l'on entraine un modèle de machine on souhaite minimiser l'erreur de prédiction sur les données non utilisées lors de l'entrainement. Pour faire cela, il existe généralement \n",
    "plusieurs paramètres propres à chaque modèle que l'on peut faire varier de sorte à influer sur les performances. On utilise plus souvent le terme d'*hyperparamètre* que l'on cherche à *calibrer* (*fine-tune*), c'est-à-dire déterminer la combinaison d'hyperparamètres qui obtient la meilleure performance. Pour pouvoir calibrer ces hyperparamètres nous avons besoins de connaitre quels sont ceux des modèles Ra&ndom Forest, pour cela on peut utiliser la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rfr['regression'].get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15b3c070",
   "metadata": {},
   "source": [
    "On voit que `scikit-learn` fournit directement des valeurs par défauts pour ces hyperparamètres et ces valeurs par défaut sont généralement des bonnes valeurs pour commencer. En plus de ces paramètres par défaut nous allons également tester d'autres combinaisons avec la méthode dites de *grid search* qui consiste simplement à tester toutes les combinaisons possibles parmi un ensemble de valeurs pour chaque paramètre à optimiser. Pour le moment nous allons choisir les paramètres `n_estimators` et `max_leaf_nodes` dont vous pouvez retrouver la signification dans la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_estimators\": [50, 100, 200],\n",
    "    \"regression__max_leaf_nodes\": [5, 10, 50, None]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e80447f9",
   "metadata": {},
   "source": [
    "De sorte à limiter l'*overfitting* en calibrant les hyperparamètres nous allons également utiliser la méthode de *cross-validation* à 5 blocs (qui est très bien expliquée [ici](https://scikit-learn.org/stable/modules/cross_validation.html)). Pour effectuer tout cela, `scikit-learn` fournit une nouvelle fois une fonction particulièrement utile : `GridSearchCV()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rfr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e7b84b6",
   "metadata": {},
   "source": [
    "**Question 14:** Pouvez vous deviner le nombre de `fit` total que nous allons effectuer lorsque nous allons appeler la méthode `fit` sur l'objet `pipe_rfr` ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35a3a97b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "Pour le grid search nous avons $3*4=12$ modèles à entrainer. Cependant, pour chaque combinaison nous effectuons une cross validation à $5$ blocs ce qui implique 5 entrainements pour chaque combinaisons tester. A la fin, nous avons donc à entrainer $60$ modèles.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24938648",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b67b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meilleure combinaison retenue: {rfr.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03435da8",
   "metadata": {},
   "source": [
    "Il est possible d'accéder aux résultats de tous les modèles entrainés afin de comparer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_random_forest = pd.DataFrame(rfr.cv_results_)\n",
    "perf_random_forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b96664",
   "metadata": {},
   "source": [
    "**Question 15:** Calculez les mêmes métriques que pour la régression linéaire et comparez la performance entre les deux modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14977a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bfc903d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4ad079",
   "metadata": {},
   "source": [
    "**Question 16:** Reproduisez le graphique représentant les valeurs prédites par rapport aux vraies valeurs et observez visuellement la différence de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff5a5f7d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80976560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b39f83b",
   "metadata": {},
   "source": [
    "### 3.2 D'autres méthodes de machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b78aa4a7",
   "metadata": {},
   "source": [
    "L'une des grandes forces de `scikit-learn` est que tout a été pensé pour que les fonctions soient extrêmement modulaire. Ainsi, une fois que l'on a un preprocessing bien défini, il est très facile de tester différents modèles pour savoir lesquels sont les mieux adaptés à nos jeux de données. Nous allons maintenant appliquer 3 autres méthodes, à savoir : \n",
    "- Les **Support Vectors Machines** (SVM) : documentation [ici](https://scikit-learn.org/stable/modules/svm.html),\n",
    "- L'**eXtreme Gradient Boosting** (XGBoost) : documentation [ici](https://xgboost.readthedocs.io/en/stable/),\n",
    "- La régression par les **plus proches voisins** (KNN) : documentation [ici](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html),\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db1f38fb",
   "metadata": {},
   "source": [
    "**Question 17:** En reprenant la même trame que pour la méthode des *Random Forests*, essayez de trouver le modèle le plus performant en utilisant les **SVM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cc080d6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pipeline_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__C\": np.logspace(-8, 8, 9, base=2), \n",
    "    \"regression__kernel\": [\"rbf\"],\n",
    "    \"regression__gamma\": [0.01],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_svr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "svr = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {svr.best_params_}\")\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "pipeline_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__C\": np.logspace(-8, 8, 9, base=2), \n",
    "    \"regression__kernel\": [\"rbf\"],\n",
    "    \"regression__gamma\": [0.01],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_svr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "svr = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {svr.best_params_}\")\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a335daaf",
   "metadata": {},
   "source": [
    "**Question 18:** De même, essayez de trouver le modèle le plus performant en utilisant le **XGBoost**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c8808bf",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917236c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b49890a4",
   "metadata": {},
   "source": [
    "**Question 19:** De même, essayez de trouver le modèle le plus performant en utilisant les **K plus proches voisins**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "674903c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_knn, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "knn = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {knn.best_params_}\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d789b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_knn, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "knn = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {knn.best_params_}\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1ad2743",
   "metadata": {},
   "source": [
    "## 4. Pour aller plus loin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57de157a",
   "metadata": {},
   "source": [
    "Précédemment nous avons réalisé que des tâches de régression. Les méthodes de machine learning peuvent aussi s'avérer particulièrement efficace pour effectuer des tâches de classification. Pour illustrer nos propos, essayons de transformer notre problème de régression en un problème de classification. \n",
    "Les valeurs de l'indice de masse corporelle peuvent donner lieu à plusieurs interprétations que l'on peut résumer dans le tableau suivant :\n",
    "\n",
    "| IMC ($kg/m^2$) | Interprétation | Classe |\n",
    "| --- | --- | --- |\n",
    "|  $< 16.5$ | Dénutrition | 0 |\n",
    "|  $16.5$ à $18.5$| Maigreur | 1 |\n",
    "|  $18.5$ à $25$| Poids normal | 2 |\n",
    "|  $25$ à $30$| Surpoids | 3 |\n",
    "|  $30$ à $35$| Obésité modérée | 4 |\n",
    "|  $35$ à $40$| Obésité sévère | 5 |\n",
    "|  $> 40$ | Obésité morbide | 6 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b068efb",
   "metadata": {},
   "source": [
    "**Question 20:** Créer deux variables `y_train_class` et `y_test_class` de sorte à ce les valeurs des IMC soient remplacées par la classe à laquelle ils appartiennt. Par exemple, si l'IMC est égal à 23 alors on renverra la valeur 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36883c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class = # VOTRE CODE\n",
    "y_test_class = # VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec55fae3",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "y_train_class = y_train.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )\n",
    "\n",
    "y_test_class = y_test.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5165be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class = y_train.apply(\n",
    "        lambda imc: 0\n",
    "        if imc < 16.5\n",
    "        else 1\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 2\n",
    "        if 18.5 <= imc < 25\n",
    "        else 3\n",
    "        if 25 <= imc < 30\n",
    "        else 4\n",
    "        if 30 <= imc < 35\n",
    "        else 5\n",
    "        if 35 <= imc < 40\n",
    "        else 6\n",
    "    )\n",
    "\n",
    "y_test_class = y_test.apply(\n",
    "        lambda imc: 0\n",
    "        if imc < 16.5\n",
    "        else 1\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 2\n",
    "        if 18.5 <= imc < 25\n",
    "        else 3\n",
    "        if 25 <= imc < 30\n",
    "        else 4\n",
    "        if 30 <= imc < 35\n",
    "        else 5\n",
    "        if 35 <= imc < 40\n",
    "        else 6\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fce3be91",
   "metadata": {},
   "source": [
    "**Question 21:** Essayez plusieurs de méthodes de machine learning de classification sur ce nouveau problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd76772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A VOUS DE JOUER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0ecde79",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquer pour voir une proposition de solution </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classification', XGBClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"classification__max_leaves\": [5, 10, 25],\n",
    "    \"classification__max_depth\": [2, 3, 5],\n",
    "    \"classification__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"classification__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"f1_weighted\"],\n",
    "                         refit=\"f1_weighted\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train_class)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    xgb,\n",
    "    X_test,\n",
    "    y_test_class,\n",
    "    cmap=plt.cm.Blues,\n",
    "    normalize=\"true\",\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ade93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classification', XGBClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"classification__max_leaves\": [5, 10, 25],\n",
    "    \"classification__max_depth\": [2, 3, 5],\n",
    "    \"classification__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"classification__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"f1_weighted\"],\n",
    "                         refit=\"f1_weighted\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train_class)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    xgb,\n",
    "    X_test,\n",
    "    y_test_class,\n",
    "    cmap=plt.cm.Blues,\n",
    "    normalize=\"true\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1da60b5",
   "metadata": {},
   "source": [
    "**Pour aller plus loin:** Comparez les performances de classification entre votre meilleur modèle de classification et votre meilleur modèle de régression pour lequel vous reconstruisez les classes prédites selon la valeurs exactes prédites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419629a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
